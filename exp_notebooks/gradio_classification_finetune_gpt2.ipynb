{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qpacV6IHuWLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c75ce9-7bcd-4bed-a1a7-a78c0c192802"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vocab_size': 50257,\n",
              " 'context_length': 1024,\n",
              " 'drop_rate': 0.0,\n",
              " 'qkv_bias': True,\n",
              " 'emb_dim': 768,\n",
              " 'n_layers': 12,\n",
              " 'n_heads': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"In the midst of winter, \"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "\n",
        "\n",
        "BASE_CONFIG"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. GPT2 Architecture"
      ],
      "metadata": {
        "id": "xrAAMF3fugyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1\n",
        "\n",
        "- Let's load:\n",
        "  1. `MultiHeadAttention` class\n",
        "  2. `LayerNorm` class\n",
        "  3. `GELU` class\n",
        "  4. `FeedForward` class\n",
        "  5. `TransformerBlock` class\n",
        "  6. `GPT2Model` class"
      ],
      "metadata": {
        "id": "NbVsuqzrulez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_embedding_dim,\n",
        "                 output_embedding_dim,\n",
        "                 context_length,\n",
        "                 dropout,\n",
        "                 num_heads,\n",
        "                 qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (output_embedding_dim % num_heads == 0), \\\n",
        "            \"output_embedding_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.output_embedding_dim = output_embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = output_embedding_dim // num_heads\n",
        "        self.W_query = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                                 bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                               bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                                 bias=qkv_bias)\n",
        "        self.output_projection = nn.Linear(output_embedding_dim,\n",
        "                                           output_embedding_dim)  # to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch, num_tokens, input_embedding_dim = inputs.shape\n",
        "\n",
        "        # qkv shapes : (batch, num_tokens, output_embedding_dim)\n",
        "        keys = self.W_key(inputs)\n",
        "        values = self.W_value(inputs)\n",
        "        queries = self.W_query(inputs)\n",
        "\n",
        "        # qkv shapes : (batch, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # qkv shapes : (batch, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "\n",
        "        # compute attention scores for each head\n",
        "        attention_scores = queries @ keys.transpose(3, 2)\n",
        "        attention_scores.masked_fill_(\n",
        "            self.mask.bool()[:num_tokens, :num_tokens], - torch.inf)\n",
        "\n",
        "        # compute attention weights + dropout\n",
        "        masked_attention_weight = torch.softmax(\n",
        "            attention_scores / (keys.shape[-1] ** 0.5),\n",
        "            dim=-1)\n",
        "        masked_attention_dropout_weight = self.dropout(masked_attention_weight)\n",
        "\n",
        "        # compute context vectors\n",
        "        # shape : (batch, num_tokens, num_heads, head_dim)\n",
        "        context_vector = (masked_attention_dropout_weight @ values).transpose(1, 2)\n",
        "\n",
        "        # combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        # shape : (batch, num_tokens, output_embedding_dim)\n",
        "        context_vector = context_vector.contiguous().view(\n",
        "            batch, num_tokens, self.output_embedding_dim)\n",
        "\n",
        "        # linear projection (optional)\n",
        "        context_vector = self.output_projection(context_vector)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.epsilon = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1,\n",
        "                    unbiased=False,  # Bessel's correction (n-1)\n",
        "                    keepdim=True)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.epsilon)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(config[\"emb_dim\"],  # 768\n",
        "                      4 * config[\"emb_dim\"]),  # 3072\n",
        "            GELU(),  # 3072\n",
        "            nn.Linear(4 * config[\"emb_dim\"],  # 3072\n",
        "                      config[\"emb_dim\"])  # 768\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(input_embedding_dim=config[\"emb_dim\"],\n",
        "                                            output_embedding_dim=config[\"emb_dim\"],\n",
        "                                            context_length=config[\"context_length\"],\n",
        "                                            dropout=config[\"drop_rate\"],\n",
        "                                            num_heads=config[\"n_heads\"],\n",
        "                                            qkv_bias=config[\"qkv_bias\"])\n",
        "        self.feed_forward = FeedForward(config)\n",
        "        self.layer_norm1 = LayerNorm(config[\"emb_dim\"])\n",
        "        self.layer_norm2 = LayerNorm(config[\"emb_dim\"])\n",
        "        self.drop_skip = nn.Dropout(config[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # skip connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.attention(x)  # shape: [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_skip(x)\n",
        "        x = shortcut + x  # skip connection\n",
        "\n",
        "        # skip connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.drop_skip(x)\n",
        "        x = shortcut + x  # skip connection\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPT2Model(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.token_emb = nn.Embedding(config[\"vocab_size\"],\n",
        "                                      config[\"emb_dim\"])\n",
        "        self.position_emb = nn.Embedding(config[\"context_length\"],\n",
        "                                         config[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(config[\"drop_rate\"])\n",
        "\n",
        "        self.transformer_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(config) for _ in range(config[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(config[\"emb_dim\"])\n",
        "\n",
        "        self.out_head = nn.Linear(config[\"emb_dim\"],\n",
        "                                  config[\"vocab_size\"],\n",
        "                                  bias=False)\n",
        "\n",
        "    def forward(self, input_token):\n",
        "        batch_size, sequence_length = input_token.shape\n",
        "        token_embeds = self.token_emb(input_token)\n",
        "        position_embeds = self.position_emb(\n",
        "            torch.arange(sequence_length,\n",
        "                         device=input_token.device))\n",
        "        embeds = token_embeds + position_embeds\n",
        "        x = self.drop_emb(embeds)\n",
        "        x = self.transformer_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GPT2DatasetV1(Dataset):\n",
        "  def __init__(self,\n",
        "               text,\n",
        "               tokenizer,\n",
        "               context_length, # length of each input vector\n",
        "               stride # chunk the text into overlapping sequence of context_length\n",
        "               ):\n",
        "    self.input_id_vectors = []\n",
        "    self.target_id_vectors = []\n",
        "\n",
        "    # tokenize the entire text\n",
        "    token_list = tokenizer.encode(text)\n",
        "\n",
        "    # append input and target vectors\n",
        "    for i in range(0, len(token_list) - context_length, stride):\n",
        "      input_vector = token_list[i:i+context_length]\n",
        "      target_vector = token_list[i+1:i+context_length+1]\n",
        "      self.input_id_vectors.append(torch.tensor(input_vector))\n",
        "      self.target_id_vectors.append(torch.tensor(target_vector))\n",
        "\n",
        "  # get the number of input vectors\n",
        "  def __len__(self):\n",
        "    return len(self.input_id_vectors)\n",
        "\n",
        "  # return the (input vector, target vector) pair\n",
        "  def __getitem__(self, id):\n",
        "    return self.input_id_vectors[id], self.target_id_vectors[id]\n",
        "\n",
        "\n",
        "\n",
        "def create_dataloader_V1(text,\n",
        "                 batch_size=4,\n",
        "                 context_length=256,\n",
        "                 stride=128,\n",
        "                 shuffle=True, # shuffle dataset\n",
        "                 drop_last=True, # drop last batch if it not equal required size\n",
        "                 num_workers=0 # number of CPU processes for preprocessing\n",
        "                 ):\n",
        "\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "  dataset = GPT2DatasetV1(text=text,\n",
        "                          tokenizer=tokenizer,\n",
        "                          context_length=context_length,\n",
        "                          stride=stride)\n",
        "\n",
        "  dataloader = DataLoader(dataset=dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=shuffle,\n",
        "                          drop_last=drop_last,\n",
        "                          num_workers=num_workers)\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "y4Py46X4uaay"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Training and Evaluation Functions\n",
        "\n",
        "- Let's load:\n",
        "  1. `train_model_simple`: without warmup rate, cosine decay, gradient clipping\n",
        "  2. `train_model`\n",
        "  3. `evaluate_model`"
      ],
      "metadata": {
        "id": "K9gMF509u4Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_model_simple(model,\n",
        "                       train_loader,\n",
        "                       val_loader,\n",
        "                       optimizer,\n",
        "                       device,\n",
        "                       num_epochs,\n",
        "                       eval_freq,\n",
        "                       eval_iter,\n",
        "                       start_context,\n",
        "                       tokenizer):\n",
        "\n",
        "  # initialize lists to track losses and tokens seen\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  track_tokens_seen = []\n",
        "  token_seen = 0\n",
        "  global_step = -1\n",
        "\n",
        "  # main training loop - iterate over training epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate over batches in each training epoch\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      # reset loss gradients from previous batch iteration\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # calculate loss on current batch\n",
        "      loss = calc_loss_batch(input_batch,\n",
        "                             target_batch,\n",
        "                             model,\n",
        "                             device)\n",
        "\n",
        "      # backward pass to calculate loss gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # update model weights using loss gradients\n",
        "      optimizer.step()\n",
        "      token_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "\n",
        "      # optional evaluation step\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model,\n",
        "                                              train_loader,\n",
        "                                              val_loader,\n",
        "                                              device,\n",
        "                                              eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(token_seen)\n",
        "        # print training and evaluation set loss\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "              f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "    # generative sample text for visual inspection\n",
        "    generate_and_print_sample(model,\n",
        "                              tokenizer,\n",
        "                              device,\n",
        "                              start_context)\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ORIG_BOOK_VERSION = False\n",
        "def train_model(model,\n",
        "                train_loader,\n",
        "                val_loader,\n",
        "                optimizer,\n",
        "                device,\n",
        "                n_epochs,\n",
        "                eval_freq,\n",
        "                eval_iter,\n",
        "                start_context,\n",
        "                tokenizer,\n",
        "                warmup_steps,\n",
        "                initial_lr=3e-05,\n",
        "                min_lr=1e-6):\n",
        "\n",
        "  train_losses, val_losses = [], []\n",
        "  track_tokens_seen, track_lrs = [], []\n",
        "\n",
        "  token_seen = 0\n",
        "  global_step = -1\n",
        "\n",
        "  # retrieve the maximum/peak learning rate from the optimizer\n",
        "  peak_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "  # calculate the total number of iterations in the training process\n",
        "  total_training_steps = len(train_loader) * n_epochs\n",
        "\n",
        "  # calculate the learning rate increment during the warmup phase\n",
        "  lr_increment = (peak_lr - initial_lr) / warmup_steps\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      global_step += 1\n",
        "\n",
        "      # adjust the learning rate based on the current phase (warmup or cosine)\n",
        "      if global_step < warmup_steps:\n",
        "        lr = initial_lr + global_step * lr_increment\n",
        "      else:\n",
        "        # cosine annealing after warmup\n",
        "        progress = ((global_step - warmup_steps) /\n",
        "                    (total_training_steps - warmup_steps))\n",
        "        lr = (min_lr +\n",
        "         (peak_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress)))\n",
        "\n",
        "      # apply the calculated learning rate to the optimizer\n",
        "      for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "      track_lrs.append(lr) # store the current learning rate\n",
        "\n",
        "      # calculate and backpropagate the loss\n",
        "      loss = calc_loss_batch(input_batch,\n",
        "                             target_batch,\n",
        "                             model,\n",
        "                             device)\n",
        "      loss.backward()\n",
        "\n",
        "      # apply gradient clipping after the warmup phase to avoid exploding gradients\n",
        "      if ORIG_BOOK_VERSION:\n",
        "        if global_step > warmup_steps:\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "      else:\n",
        "        # the book originally used global_step > warmup_steps, which led to a skipped clipping step after warmup\n",
        "        if global_step >= warmup_steps:\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "      optimizer.step()\n",
        "      token_seen += input_batch.numel()\n",
        "\n",
        "      # periodically evaluate the model on the training and validation sets\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model,\n",
        "                                              train_loader,\n",
        "                                              val_loader,\n",
        "                                              device,\n",
        "                                              eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(token_seen)\n",
        "        # print the current losses\n",
        "        print(f\"Ep {epoch+1} (Iter {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, \"\n",
        "                      f\"Val loss {val_loss:.3f}\")\n",
        "\n",
        "    # generate and print a sample from the model to monitor progess\n",
        "    generate_and_print_sample(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=device,\n",
        "        start_context=start_context\n",
        "    )\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen, track_lrs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model(model,\n",
        "                    train_loader,\n",
        "                    val_loader,\n",
        "                    device,\n",
        "                    eval_iter):\n",
        "  # set model to evaluation mode\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # calculate loss\n",
        "    train_loss = calc_loss_loader(train_loader,\n",
        "                                  model,\n",
        "                                  device,\n",
        "                                  num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader,\n",
        "                                model,\n",
        "                                device,\n",
        "                                num_batches=eval_iter)\n",
        "\n",
        "  # set model back to training mode\n",
        "  model.train()\n",
        "  return train_loss, val_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "\n",
        "\n",
        "def calc_loss_batch(input_batch,\n",
        "                    target_batch,\n",
        "                    model,\n",
        "                    device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1),\n",
        "                                           target_batch.flatten())\n",
        "  return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(dataloader,\n",
        "                     model,\n",
        "                     device,\n",
        "                     num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(dataloader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(dataloader)\n",
        "  else:\n",
        "    # reduce the number of batches to match the total number of batches in the data loader\n",
        "    # if num_batches exceeds the number of batches in the data loader\n",
        "    num_batches = min(num_batches, len(dataloader))\n",
        "  for i, (input_batch, target_batch) in enumerate(dataloader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(input_batch,\n",
        "                             target_batch,\n",
        "                             model,\n",
        "                             device)\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches\n",
        "\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model,\n",
        "                              tokenizer,\n",
        "                              device,\n",
        "                              start_context):\n",
        "  # set model to evaluation mode\n",
        "  model.eval()\n",
        "  context_size = model.position_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(model=model,\n",
        "                                     input_batch=encoded,\n",
        "                                     max_new_tokens=50,\n",
        "                                     context_size=context_size)\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \")) # compact print format\n",
        "  # set model back to training mode\n",
        "  model.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "  # turn the list of token IDs into tensor with batch dimension\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(encoded_tensor, tokenizer):\n",
        "  # turn tensor without batch dimension to list\n",
        "  token_ids = encoded_tensor.squeeze(0).tolist()\n",
        "  text = tokenizer.decode(token_ids)\n",
        "  return text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_text_simple(model,\n",
        "                         input_batch,  # [batch, num_tokens]\n",
        "                         max_new_tokens,  # numbers of new tokens to be predicted\n",
        "                         context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        # crop current context if it exceeds the supported context_size\n",
        "        crop_input_batch = input_batch[:, -context_size:]\n",
        "\n",
        "        # predict next token\n",
        "        with torch.no_grad():\n",
        "            logits = model(crop_input_batch)\n",
        "\n",
        "        # consider only logits of the last token\n",
        "        logits = logits[:, -1, :]  # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "        predicted_tokens = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "        # update input_batch (append predicted tokens to the sequences)\n",
        "        input_batch = torch.cat([input_batch, predicted_tokens], dim=-1)  # [batch, num_tokens+1]\n",
        "\n",
        "    return input_batch\n",
        "\n",
        "\n",
        "\n",
        "def generate_text(model,\n",
        "                  input_batch,\n",
        "                  max_new_tokens,\n",
        "                  context_size,\n",
        "                  temperature=0.0,\n",
        "                  top_k=None,\n",
        "                  eos_id=None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    # crop current context if it exceeds the supported context_size\n",
        "    crop_input_batch = input_batch[:, -context_size:]\n",
        "\n",
        "    # predict next token\n",
        "    with torch.no_grad():\n",
        "      logits = model(crop_input_batch)\n",
        "\n",
        "    # consider only logits of the last token\n",
        "    logits = logits[:, -1, :] # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
        "\n",
        "    # NEW: filter logits with top_k sampling\n",
        "    if top_k is not None:\n",
        "      # keep only top_k values\n",
        "      top_logits, _ = torch.topk(logits, top_k)\n",
        "      min_val = top_logits[:, -1] # min value among the top_k values\n",
        "      # all values other than top_k values will be set to -inf\n",
        "      logits = torch.where(logits < min_val,\n",
        "                           torch.tensor(-torch.inf).to(logits.device),\n",
        "                           logits)\n",
        "\n",
        "    # NEW: temperature scaling\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "\n",
        "      probas = torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
        "      predicted_tokens = torch.multinomial(probas, num_samples=1) # (batch, 1)\n",
        "\n",
        "    else: # same as before\n",
        "      #probas = torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
        "      predicted_tokens = torch.argmax(logits, dim=-1, keepdim=True) # (batch, 1)\n",
        "\n",
        "    if predicted_tokens == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "    # update input_batch (append predicted tokens to the sequences)\n",
        "    input_batch = torch.cat([input_batch, predicted_tokens], dim=1) # [batch, num_tokens+1]\n",
        "\n",
        "  return input_batch\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################"
      ],
      "metadata": {
        "id": "7aAorxrHuaYL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 LoRA layer"
      ],
      "metadata": {
        "id": "2ujalGwqvNov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "class LoRALayer(torch.nn.Module):\n",
        "  def __init__(self, in_dim, out_dim, rank, alpha):\n",
        "    super().__init__()\n",
        "    self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
        "    # Kaiming/He uniform initialization, similar to standard weight initialization\n",
        "    torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
        "    self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
        "    self.alpha = alpha\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.alpha * (x @ self.A @ self.B)\n",
        "    return x\n",
        "\n",
        "\n",
        "class LinearLayerWithLoRA(torch.nn.Module):\n",
        "  def __init__(self, linear, rank, alpha):\n",
        "    super().__init__()\n",
        "    self.linear = linear\n",
        "    self.lora = LoRALayer(linear.in_features,\n",
        "                          linear.out_features,\n",
        "                          rank,\n",
        "                          alpha)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x) + self.lora(x)\n",
        "\n",
        "\n",
        "\n",
        "def replace_linear_with_lora(model, rank, alpha):\n",
        "  for name, module in model.named_children():\n",
        "    if isinstance(module, torch.nn.Linear):\n",
        "      print(f\"Replacing {name} with LinearLayerWithLoRA\")\n",
        "      setattr(model, name, LinearLayerWithLoRA(module, rank, alpha))\n",
        "    else:\n",
        "      # recursively apply the same function to child modules\n",
        "      replace_linear_with_lora(module, rank, alpha)"
      ],
      "metadata": {
        "id": "gkGLSDbguaVh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Load weights"
      ],
      "metadata": {
        "id": "Ir_ddY8UR_9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.position_emb.weight = assign(gpt.position_emb.weight, params['wpe'])\n",
        "    gpt.token_emb.weight = assign(gpt.token_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.transformer_blocks[b].attention.W_query.weight = assign(\n",
        "            gpt.transformer_blocks[b].attention.W_query.weight, q_w.T)\n",
        "        gpt.transformer_blocks[b].attention.W_key.weight = assign(\n",
        "            gpt.transformer_blocks[b].attention.W_key.weight, k_w.T)\n",
        "        gpt.transformer_blocks[b].attention.W_value.weight = assign(\n",
        "            gpt.transformer_blocks[b].attention.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.transformer_blocks[b].attention.W_query.bias = assign(\n",
        "            gpt.transformer_blocks[b].attention.W_query.bias, q_b)\n",
        "        gpt.transformer_blocks[b].attention.W_key.bias = assign(\n",
        "            gpt.transformer_blocks[b].attention.W_key.bias, k_b)\n",
        "        gpt.transformer_blocks[b].attention.W_value.bias = assign(\n",
        "            gpt.transformer_blocks[b].attention.W_value.bias, v_b)\n",
        "\n",
        "        gpt.transformer_blocks[b].attention.output_projection.weight = assign(\n",
        "            gpt.transformer_blocks[b].attention.output_projection.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.transformer_blocks[b].attention.output_projection.bias = assign(\n",
        "            gpt.transformer_blocks[b].attention.output_projection.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.transformer_blocks[b].feed_forward.layers[0].weight = assign(\n",
        "            gpt.transformer_blocks[b].feed_forward.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.transformer_blocks[b].feed_forward.layers[0].bias = assign(\n",
        "            gpt.transformer_blocks[b].feed_forward.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.transformer_blocks[b].feed_forward.layers[2].weight = assign(\n",
        "            gpt.transformer_blocks[b].feed_forward.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.transformer_blocks[b].feed_forward.layers[2].bias = assign(\n",
        "            gpt.transformer_blocks[b].feed_forward.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.transformer_blocks[b].layer_norm1.scale = assign(\n",
        "            gpt.transformer_blocks[b].layer_norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.transformer_blocks[b].layer_norm1.shift = assign(\n",
        "            gpt.transformer_blocks[b].layer_norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.transformer_blocks[b].layer_norm2.scale = assign(\n",
        "            gpt.transformer_blocks[b].layer_norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.transformer_blocks[b].layer_norm2.shift = assign(\n",
        "            gpt.transformer_blocks[b].layer_norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "3YkWo22WSF6_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Dataset\n",
        "- We'll use `war-and-peace.txt` dataset"
      ],
      "metadata": {
        "id": "F8M8MdgZvwXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Gradio app"
      ],
      "metadata": {
        "id": "I5WNdNN6v2Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Finetune"
      ],
      "metadata": {
        "id": "fJpCE8hWR152"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Clean up GPU memory ---\n",
        "import gc\n",
        "# del train_loss, val_loss  # if you don't need them anymore\n",
        "#del train_dataloader, val_dataloader  # optional, if not reused\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ],
      "metadata": {
        "id": "yN1VxY6jRs-3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "e444191d-39e5-440a-d462-258a3b095c0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-1835142963.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipc_collect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mipc_collect\u001b[0;34m()\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mtensors\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrelease\u001b[0m \u001b[0munused\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \"\"\"\n\u001b[0;32m--> 997\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_ipc_collect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "try:\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
        "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
        "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nzuUhcUUaeE",
        "outputId": "b41d26d9-6c84-4ff6-b768-b6745d147672"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4pbQJq99Uaa6",
        "outputId": "73f7bf63-5a1e-4204-afac-4b500f7870c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aab0a573-e94f-4105-88e9-3359e3227e2b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aab0a573-e94f-4105-88e9-3359e3227e2b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aab0a573-e94f-4105-88e9-3359e3227e2b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aab0a573-e94f-4105-88e9-3359e3227e2b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7ef0a076-f27b-428f-b142-5218a4d5ef57\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ef0a076-f27b-428f-b142-5218a4d5ef57')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7ef0a076-f27b-428f-b142-5218a4d5ef57 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f1195f3f-4c58-4a99-a3c7-dd403d83dee8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f1195f3f-4c58-4a99-a3c7-dd403d83dee8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhbihDxQUaY8",
        "outputId": "016a8550-321f-4943-e403-2f256612854b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_balanced_dataset(df):\n",
        "  # count the instances of `spam`\n",
        "  num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "  # randomly sub-sample \"ham\" with `num_spam` rows\n",
        "  ham_sub = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "  # concatenate subsets\n",
        "  balanced_df = pd.concat([ham_sub, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "  return balanced_df\n",
        "\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "\n",
        "# show first 5 and last 5 rows\n",
        "print(balanced_df.iloc[np.r_[0:5, -5:0]])\n",
        "\n",
        "# check label/class distribution\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHyD0PzQUaWg",
        "outputId": "6f4984eb-f328-4a0b-cddb-2b2d039e8773"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Label                                               Text\n",
            "4307   ham  Awww dat is sweet! We can think of something t...\n",
            "4138   ham                             Just got to  &lt;#&gt;\n",
            "4831   ham  The word \"Checkmate\" in chess comes from the P...\n",
            "4461   ham  This is wishing you a great day. Moji told me ...\n",
            "5440   ham      Thank you. do you generally date the brothas?\n",
            "5537  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
            "5540  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
            "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
            "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "# show first 5 and last 5 rows\n",
        "print(balanced_df.iloc[np.r_[0:5, -5:0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9MObkQxUaUM",
        "outputId": "9e06dd99-14a7-4185-b808-4e5307398f49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Label                                               Text\n",
            "4307      0  Awww dat is sweet! We can think of something t...\n",
            "4138      0                             Just got to  &lt;#&gt;\n",
            "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
            "4461      0  This is wishing you a great day. Moji told me ...\n",
            "5440      0      Thank you. do you generally date the brothas?\n",
            "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
            "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
            "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
            "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
            "5567      1  This is the 2nd time we have tried 2 contact u...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "\n",
        "  # shuffle dataset\n",
        "  df = df.sample(frac=1, random_state=211).reset_index(drop=True)\n",
        "\n",
        "  # compute split range\n",
        "  train_end = int(len(df) * train_frac)\n",
        "  validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "  # split\n",
        "  train_df = df[:train_end]\n",
        "  validation_df = df[train_end:validation_end]\n",
        "  test_df = df[validation_end:]\n",
        "\n",
        "  return train_df, validation_df, test_df\n",
        "\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "\n",
        "\n",
        "# save splitted dataframe into csv files\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "Y84esRrmUaR5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "  def __init__(self,\n",
        "               csv_file,\n",
        "               tokenizer,\n",
        "               max_length=None,\n",
        "               pad_token_id=50256):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "\n",
        "    # pre-tokenizer texts\n",
        "    self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
        "\n",
        "    if max_length is None:\n",
        "      self.max_length = self._longest_encoded_length()\n",
        "    else:\n",
        "      self.max_length = max_length\n",
        "      # truncate sequences if they're longer than max_length\n",
        "      self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
        "\n",
        "    # pad tokens\n",
        "    self.encoded_texts = [\n",
        "        encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "        for encoded_text in self.encoded_texts\n",
        "    ]\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    encoded_sequence = self.encoded_texts[index]\n",
        "    label = self.data.iloc[index][\"Label\"]\n",
        "    return (\n",
        "        torch.tensor(encoded_sequence, dtype=torch.long),\n",
        "        torch.tensor(label, dtype=torch.long)\n",
        "    )\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def _longest_encoded_length(self):\n",
        "    return max(len(encoded_text) for encoded_text in self.encoded_texts)"
      ],
      "metadata": {
        "id": "VB9rJ8puUaPy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "SmBBk36PZOzW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)\n",
        "\n",
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzUOmiyfUaNW",
        "outputId": "cfe7cde9-0b2d-451e-9a7e-c4889cb00df0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(211)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "rvrSx3_xU3YA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1JOWp1dU3Vg",
        "outputId": "bffa0ba7-e4d5-4e7d-fd14-fe98f298469b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DpF1G6sU3TH",
        "outputId": "3a26f87a-4232-4123-90be-3ee50c337447"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/\"\n",
        "    \"LLMs-from-scratch/main/ch05/\"\n",
        "    \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split(\"/\")[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOg1UySsU3Qm",
        "outputId": "d1ff5ce6-5bea-4c16-ae1a-df116d1bee75"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7d8486cd9c50>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "V4_EFh54U3OX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "model_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wQiM_VybU3MF",
        "outputId": "fc3d7c4b-2522-459c-d28f-10a001c47d87"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'124M'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "print(settings)\n",
        "print(params.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rnXssd3U3Jb",
        "outputId": "fc403828-8c32-427f-eb8e-43f1749932bf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 193kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 695kiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 157kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [02:08<00:00, 3.86MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 8.66MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 403kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 390kiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2Model(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "0H3WrlbvU3HH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"In the midst of winter\"\n",
        "\n",
        "token_ids = generate_text(\n",
        "    model=model,\n",
        "    input_batch=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=50,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    temperature = 2.0,\n",
        "    top_k = 10\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7fS9AjcU3E0",
        "outputId": "2e333707-fe88-499b-a5ef-5cf9aaed1c14"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the midst of winter break I was sitting with two friends who I would call friends and would say 'I love you so so much. It's been really nice to see that you guys care.' It's been really nice for the rest of us.\" She's not exactly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text(\n",
        "    model=model,\n",
        "    input_batch=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xddYdjWXU3CL",
        "outputId": "d9229d16-3792-4908-af8d-8639d46924e2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "rApoieoOVYj8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(211)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ],
      "metadata": {
        "id": "rlPFuWFzVYht"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.transformer_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "Tl_UiIsoVYfa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVwYolA4VYdG",
        "outputId": "3ff1050a-0417-4ea7-bc3c-75456a42d650"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(\n",
        "    model,\n",
        "    input_size=(1, BASE_CONFIG[\"context_length\"]),      # (batch, seq_len)\n",
        "    dtypes=[torch.long],                                # token IDs are int64\n",
        "    col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n",
        "    row_settings=(\"depth\", \"var_names\"),                # valid row options\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwMR3qtAVYay",
        "outputId": "7c81f95b-b54a-45f9-f1f1-c380d1cc214a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===========================================================================================================================================================\n",
              "Layer (type (var_name):depth-idx)                       Input Shape               Output Shape              Param #                   Trainable\n",
              "===========================================================================================================================================================\n",
              "GPT2Model (GPT2Model)                                   [1, 1024]                 [1, 1024, 2]              --                        Partial\n",
              "├─Embedding (token_emb): 1-1                            [1, 1024]                 [1, 1024, 768]            (38,597,376)              False\n",
              "├─Embedding (position_emb): 1-2                         [1024]                    [1024, 768]               (786,432)                 False\n",
              "├─Dropout (drop_emb): 1-3                               [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "├─Sequential (transformer_blocks): 1-4                  [1, 1024, 768]            [1, 1024, 768]            --                        Partial\n",
              "│    └─TransformerBlock (0): 2-1                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-1                [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-2         [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-3                    [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-4                [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-5             [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-6                    [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (1): 2-2                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-7                [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-8         [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-9                    [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-10               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-11            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-12                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (2): 2-3                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-13               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-14        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-15                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-16               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-17            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-18                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (3): 2-4                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-19               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-20        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-21                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-22               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-23            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-24                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (4): 2-5                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-25               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-26        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-27                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-28               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-29            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-30                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (5): 2-6                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-31               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-32        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-33                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-34               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-35            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-36                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (6): 2-7                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-37               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-38        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-39                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-40               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-41            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-42                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (7): 2-8                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-43               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-44        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-45                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-46               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-47            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-48                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (8): 2-9                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-49               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-50        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-51                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-52               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-53            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-54                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (9): 2-10                       [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-55               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-56        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-57                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-58               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-59            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-60                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (10): 2-11                      [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
              "│    │    └─LayerNorm (layer_norm1): 3-61               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─MultiHeadAttention (attention): 3-62        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
              "│    │    └─Dropout (drop_skip): 3-63                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-64               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
              "│    │    └─FeedForward (feed_forward): 3-65            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
              "│    │    └─Dropout (drop_skip): 3-66                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    └─TransformerBlock (11): 2-12                      [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
              "│    │    └─LayerNorm (layer_norm1): 3-67               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
              "│    │    └─MultiHeadAttention (attention): 3-68        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
              "│    │    └─Dropout (drop_skip): 3-69                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "│    │    └─LayerNorm (layer_norm2): 3-70               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
              "│    │    └─FeedForward (feed_forward): 3-71            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
              "│    │    └─Dropout (drop_skip): 3-72                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
              "├─LayerNorm (final_norm): 1-5                           [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
              "├─Linear (out_head): 1-6                                [1, 1024, 768]            [1, 1024, 2]              1,538                     True\n",
              "===========================================================================================================================================================\n",
              "Total params: 124,441,346\n",
              "Trainable params: 7,090,946\n",
              "Non-trainable params: 117,350,400\n",
              "Total mult-adds (Units.MEGABYTES): 928.92\n",
              "===========================================================================================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 849.36\n",
              "Params size (MB): 497.77\n",
              "Estimated Total Size (MB): 1347.14\n",
              "==========================================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"I open myself to\")\n",
        "inputs = torch.tensor(inputs, dtype=torch.long).unsqueeze(0).to(device)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzsBf8maVYYk",
        "outputId": "8d7bfbdf-0e0a-4fd5-fe6f-d19f5a9198b4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[  40, 1280, 3589,  284]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader,\n",
        "                         model,\n",
        "                         device,\n",
        "                         num_batches=None):\n",
        "  model.eval()\n",
        "  correct_predictions, num_examples = 0, 0\n",
        "\n",
        "  if num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for batch_id, (input_batch, label_batch) in enumerate(data_loader):\n",
        "    if batch_id < num_batches:\n",
        "      input_batch, label_batch = input_batch.to(device), label_batch.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = model(input_batch)[:, -1, :] # logits of the last output token\n",
        "      predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "      num_examples += predicted_labels.shape[0]\n",
        "      correct_predictions += (predicted_labels == label_batch).sum().item()\n",
        "    else:\n",
        "      break\n",
        "  return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "AUVIaip7VYWZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(211)\n",
        "\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfQzqF06VYUK",
        "outputId": "c9a600ce-7f3e-4da5-e758-db7dc7d8459b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 51.25%\n",
            "Validation accuracy: 58.75%\n",
            "Test accuracy: 37.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch,\n",
        "                    label_batch,\n",
        "                    model,\n",
        "                    device):\n",
        "  input_batch, label_batch = input_batch.to(device), label_batch.to(device)\n",
        "  logits = model(input_batch)[:, -1, :] # logits of the last output token\n",
        "  loss = torch.nn.functional.cross_entropy(logits, label_batch)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader,\n",
        "                     model,\n",
        "                     device,\n",
        "                     num_batches=None):\n",
        "  total_loss = 0.0\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for batch_id, (input_batch, label_batch) in enumerate(data_loader):\n",
        "    if batch_id < num_batches:\n",
        "      loss = calc_loss_batch(input_batch, label_batch, model, device)\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "IF9Ckd7LVYRh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(211)\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqtik-S0VYPS",
        "outputId": "0732667c-ccb6-4ad6-939f-406768f34bd4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.533\n",
            "Validation loss: 1.299\n",
            "Test loss: 1.851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_simple(model,\n",
        "                            train_loader,\n",
        "                            val_loader,\n",
        "                            optimizer,\n",
        "                            device,\n",
        "                            num_epochs,\n",
        "                            eval_freq,\n",
        "                            eval_iter # number of batches to evaluate from\n",
        "                            ):\n",
        "  train_losses, val_losses = [], []\n",
        "  train_accuracies, val_accuracies = [], []\n",
        "  examples_seen, global_step = 0, -1\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for input_batch, label_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(input_batch, label_batch, model, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "      global_step += 1\n",
        "\n",
        "\n",
        "      # optional evaluation step\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model,\n",
        "                                              train_loader,\n",
        "                                              val_loader,\n",
        "                                              device,\n",
        "                                              eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "    # calculate accuracy after each epoch\n",
        "    train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "    val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "    print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "  return train_losses, val_losses, train_accuracies, val_accuracies, examples_seen"
      ],
      "metadata": {
        "id": "xWA_wdxuVYMu"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "training_start_time = time.time()\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "torch.manual_seed(211)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "\n",
        "training_end_time = time.time()\n",
        "runtime_in_seconds = training_end_time - training_start_time\n",
        "# format as minutes and seconds\n",
        "minutes, seconds = divmod(runtime_in_seconds, 60)\n",
        "print(f\"device: {device}\")\n",
        "print(f\"training runtime: {int(minutes)} min {seconds:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj0WTl_QVYKn",
        "outputId": "24189cfe-8346-431b-db7b-6c05faf7b6ca"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 1.530, Val loss 1.177\n",
            "Ep 1 (Step 000050): Train loss 0.637, Val loss 0.639\n",
            "Ep 1 (Step 000100): Train loss 0.522, Val loss 0.533\n",
            "Training accuracy: 80.00% | Validation accuracy: 87.50%\n",
            "Ep 2 (Step 000150): Train loss 0.412, Val loss 0.336\n",
            "Ep 2 (Step 000200): Train loss 0.224, Val loss 0.106\n",
            "Ep 2 (Step 000250): Train loss 0.028, Val loss 0.070\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Ep 3 (Step 000300): Train loss 0.124, Val loss 0.076\n",
            "Ep 3 (Step 000350): Train loss 0.124, Val loss 0.048\n",
            "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
            "Ep 4 (Step 000400): Train loss 0.075, Val loss 0.037\n",
            "Ep 4 (Step 000450): Train loss 0.194, Val loss 0.043\n",
            "Ep 4 (Step 000500): Train loss 0.171, Val loss 0.041\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Ep 5 (Step 000550): Train loss 0.045, Val loss 0.037\n",
            "Ep 5 (Step 000600): Train loss 0.021, Val loss 0.035\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 6 (Step 000650): Train loss 0.022, Val loss 0.036\n",
            "Ep 6 (Step 000700): Train loss 0.053, Val loss 0.031\n",
            "Ep 6 (Step 000750): Train loss 0.026, Val loss 0.037\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Ep 7 (Step 000800): Train loss 0.217, Val loss 0.029\n",
            "Ep 7 (Step 000850): Train loss 0.005, Val loss 0.027\n",
            "Ep 7 (Step 000900): Train loss 0.123, Val loss 0.037\n",
            "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
            "Ep 8 (Step 000950): Train loss 0.010, Val loss 0.027\n",
            "Ep 8 (Step 001000): Train loss 0.025, Val loss 0.024\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 9 (Step 001050): Train loss 0.015, Val loss 0.026\n",
            "Ep 9 (Step 001100): Train loss 0.008, Val loss 0.050\n",
            "Ep 9 (Step 001150): Train loss 0.125, Val loss 0.036\n",
            "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
            "Ep 10 (Step 001200): Train loss 0.021, Val loss 0.023\n",
            "Ep 10 (Step 001250): Train loss 0.006, Val loss 0.056\n",
            "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
            "device: cpu\n",
            "training runtime: 26 min 18.58 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"classification_finetune_{label}_gpt2.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fFviQxSDVYIW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "1FuSbl8oVYF4",
        "outputId": "1c60906d-3c4c-4261-85d3-790e78f3a4ec"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "j8NgXgRtVYDz",
        "outputId": "fd431a1e-746e-4c1f-8587-231ffc68a7d7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG_PLv5HVYBV",
        "outputId": "36789597-c997-41fb-8bac-2dd0f8ddb1fc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 98.46%\n",
            "Validation accuracy: 95.97%\n",
            "Test accuracy: 96.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(text,\n",
        "                    model,\n",
        "                    tokenizer,\n",
        "                    device,\n",
        "                    max_length=None,\n",
        "                    pad_token_id=50256):\n",
        "  model.eval()\n",
        "\n",
        "  # input preprocessing\n",
        "  input_ids = tokenizer.encode(text)\n",
        "  supported_context_length = model.position_emb.weight.shape[0]\n",
        "  input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "  input_ids += [pad_token_id] * (max_length  - len(input_ids))\n",
        "  input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
        "\n",
        "  # model inference\n",
        "  with torch.no_grad():\n",
        "    logits = model(input_tensor)[:, -1, :] # logits of the last output token\n",
        "  predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "  # return the classifier result\n",
        "  return \"spam\" if predicted_label == 1 else \"not spam\""
      ],
      "metadata": {
        "id": "jue6eveaWZgA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrXu_L3AWZdr",
        "outputId": "6e7325b1-c750-48eb-ea4b-89b4e09008c7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClM_o8msWZbZ",
        "outputId": "49a0f2bf-5046-458a-db50-c0df574775a3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model state_dict\n",
        "torch.save(model.state_dict(), \"classification_finetune_gpt2.pth\")"
      ],
      "metadata": {
        "id": "_8Mgfr_sWZY-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model state_dict\n",
        "model = GPT2Model(BASE_CONFIG)\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"classification_finetune_gpt2.pth\", map_location=device, weights_only=True))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTgI87HfWZWe",
        "outputId": "326dcaee-4cd4-4053-c608-212d0bfc6c4e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Model(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (position_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (transformer_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Gradio"
      ],
      "metadata": {
        "id": "kt-BHq9tWilz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "def generate_answer(input_prompt):\n",
        "\n",
        "  # start the timer\n",
        "  start_time = time.time()\n",
        "\n",
        "  torch.manual_seed(211)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  prediction = classify_review(input_prompt,\n",
        "                              model,\n",
        "                              tokenizer,\n",
        "                              \"cpu\",\n",
        "                              max_length=120)\n",
        "\n",
        "  # Calculate the prediction time\n",
        "  pred_time = round(time.time() - start_time, 5)\n",
        "\n",
        "  # print(\"Output text:\\n\", token_ids_to_text(token_ids, bpe_tokenizer))\n",
        "  return prediction, pred_time"
      ],
      "metadata": {
        "id": "5DqfsyN8WiX7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "examples = [\n",
        "    [\"Well done ENGLAND! Get the official poly ringtone or colour flag on yer mob\"\n",
        "    \"ile! text TONE or FLAG to 84199 NOW! Opt-out txt ENG STOP. Box39822 W111WX £1.50\"], #spam\n",
        "    [\"Hi its in durban are you still on this number\"], #ham\n",
        "    [\"Compliments to you. Was away from the system. How your side.\"], #ham\n",
        "    [\"Can ü call me at 10:10 to make sure dat i've woken up...\"], #ham\n",
        "    [\"tddnewsletter@emc1.co.uk (More games from TheDailyDraw) Dear Helen,\"\n",
        "    \" Dozens of Free Games - with great prizesWith..\"], #spam\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"# GPT2 From Scratch\")\n",
        "\n",
        "  # tab 1\n",
        "  with gr.Tab(\"Instruction Finetune GPT2 (124M)\"):\n",
        "    with gr.Row():\n",
        "      inp = gr.Textbox(label=\"Input Text\", placeholder=\"Type here...\")\n",
        "      out = [gr.Textbox(label=\"Classification\", value=\"\", interactive=False),\n",
        "            gr.Number(label=\"Time Taken (s)\"),\n",
        "            ]\n",
        "    inp.change(fn=generate_answer, inputs=inp, outputs=out)\n",
        "\n",
        "    with gr.Column():\n",
        "      gr.Examples(examples=examples, inputs=inp, label=\"📚 Examples\")\n",
        "\n",
        "\n",
        "  # tab 2\n",
        "  with gr.Tab(\"Graphs:\"):\n",
        "    with gr.Row():\n",
        "      gr.Image(value=\"classification_finetune_loss_gpt2.png\", label=\"Loss Curve\", interactive=False)\n",
        "      gr.Image(value=\"classification_finetune_accuracy_gpt2.png\", label=\"Accuracy\", interactive=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Launch the demo!\n",
        "demo.launch(debug=True, # print errors locally?\n",
        "            share=True) # generate a publically shareable URL?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "s8T7pjB8n3cm",
        "outputId": "daa2d4c9-99bf-4a39-b257-d987bc9b52d2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://0db78a2b143fac0f84.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0db78a2b143fac0f84.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://0db78a2b143fac0f84.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}