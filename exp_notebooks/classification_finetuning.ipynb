{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "notebook_start_time = time.time()"
   ],
   "metadata": {
    "id": "1CwVgnSzsX3k"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "id": "7CDG6VLJ4cci"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cgYUr06RSJFh",
    "outputId": "7223b844-ab91-46c0-873b-4229e9b183de",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 2.0.2\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0+cu124\n",
      "tensorflow version: 2.18.0\n",
      "pandas version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "        \"tiktoken\",    # Tokenizer\n",
    "        \"torch\",       # Deep learning library\n",
    "        \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "        \"pandas\"       # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Preparing the dataset\n",
    "\n"
   ],
   "metadata": {
    "id": "rvU88QLl4imS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkWX-OSs3ul0",
    "outputId": "180d1455-1939-4ce8-8ab0-f2cb08948bb9"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "jdCtLu024J1_",
    "outputId": "6578c1d6-e594-49f9-e6fe-4915240a6d03"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-09d5c0ac-1bd7-452e-94ba-e070ecd2a6f7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09d5c0ac-1bd7-452e-94ba-e070ecd2a6f7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-09d5c0ac-1bd7-452e-94ba-e070ecd2a6f7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-09d5c0ac-1bd7-452e-94ba-e070ecd2a6f7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-df80036b-6e61-4d17-8b52-2711483ec72d\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df80036b-6e61-4d17-8b52-2711483ec72d')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-df80036b-6e61-4d17-8b52-2711483ec72d button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_9cbaea1a-4ae8-473b-8a46-65baaad8f6cd\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_9cbaea1a-4ae8-473b-8a46-65baaad8f6cd button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df",
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- let's check the class distribution:"
   ],
   "metadata": {
    "id": "HIMlGFo1UgJD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(df[\"Label\"].value_counts())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8uZDsho4YHY",
    "outputId": "09efd042-65f4-4e98-ed64-69ef8a4926cf"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- now we should subsample the dataset so that we have a balanced dataset with the same number of data for `ham` and `spam`:"
   ],
   "metadata": {
    "id": "rVcpTX6mU6zj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n\\n\\n**********df['Label']**********:\\n\", df[\"Label\"].head(5))\n",
    "\n",
    "print(\"\\n\\n\\n**********df['Label'] == 'spam'**********:\\n\", df[\"Label\"].head(5) == \"spam\")\n",
    "\n",
    "print(\"\\n\\n\\n**********df[df['Label'] == 'spam']**********:\\n\", df[df[\"Label\"] == \"spam\"].head(5))\n",
    "\n",
    "print(\"\\n\\n\\n**********df[df['Label'] == 'spam'].shape**********:\\n\", df[df[\"Label\"] == \"spam\"].shape)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEjMwEcSVv2h",
    "outputId": "9038b039-9293-4dd1-e1b0-f1a6ee951705"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "\n",
      "**********df['Label']**********:\n",
      " 0     ham\n",
      "1     ham\n",
      "2    spam\n",
      "3     ham\n",
      "4     ham\n",
      "Name: Label, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "**********df['Label'] == 'spam'**********:\n",
      " 0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "Name: Label, dtype: bool\n",
      "\n",
      "\n",
      "\n",
      "**********df[df['Label'] == 'spam']**********:\n",
      "    Label                                               Text\n",
      "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "8   spam  WINNER!! As a valued network customer you have...\n",
      "9   spam  Had your mobile 11 months or more? U R entitle...\n",
      "11  spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "\n",
      "\n",
      "\n",
      "**********df[df['Label'] == 'spam'].shape**********:\n",
      " (747, 2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "  # count the instances of `spam`\n",
    "  num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "\n",
    "  # randomly sub-sample \"ham\" with `num_spam` rows\n",
    "  ham_sub = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "  # concatenate subsets\n",
    "  balanced_df = pd.concat([ham_sub, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "  return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "\n",
    "# show first 5 and last 5 rows\n",
    "print(balanced_df.iloc[np.r_[0:5, -5:0]])\n",
    "\n",
    "# check label/class distribution\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZBA8sb3Un--",
    "outputId": "ddb67742-1631-4305-b893-63133f0c554a"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Label                                               Text\n",
      "4307   ham  Awww dat is sweet! We can think of something t...\n",
      "4138   ham                             Just got to  &lt;#&gt;\n",
      "4831   ham  The word \"Checkmate\" in chess comes from the P...\n",
      "4461   ham  This is wishing you a great day. Moji told me ...\n",
      "5440   ham      Thank you. do you generally date the brothas?\n",
      "5537  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "5540  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
      "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Next, turn our \"Label\" into integer class labels:"
   ],
   "metadata": {
    "id": "5SZ_hsj0aSIU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "# show first 5 and last 5 rows\n",
    "print(balanced_df.iloc[np.r_[0:5, -5:0]])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbpLXZSTYild",
    "outputId": "e92590a1-4816-4550-f79e-b34cb9722157"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      Label                                               Text\n",
      "4307      0  Awww dat is sweet! We can think of something t...\n",
      "4138      0                             Just got to  &lt;#&gt;\n",
      "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
      "4461      0  This is wishing you a great day. Moji told me ...\n",
      "5440      0      Thank you. do you generally date the brothas?\n",
      "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
      "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567      1  This is the 2nd time we have tried 2 contact u...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Now, let's split the dataset:"
   ],
   "metadata": {
    "id": "CEhQjMvza6Yl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "balanced_df.sample(frac=0.005, # fraction of the dataset to be subsample\n",
    "                   random_state=211)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "o2ic9-HScCUY",
    "outputId": "c6e25db5-126c-4230-af88-3f3988008d97"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Label                                               Text\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "5251      0  Yeah work is fine, started last week, all the ...\n",
       "1793      1  WIN: We have a winner! Mr. T. Foley won an iPo...\n",
       "238       0             Where are you?when wil you reach here?\n",
       "4371      1  Do you want a new Video handset? 750 any time ...\n",
       "4678      0               Wewa is 130. Iriver 255. All 128 mb.\n",
       "2295      1   You have 1 new message. Please call 08718738034."
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-e56a1e78-22c6-469d-b950-644958e4a84b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>0</td>\n",
       "      <td>Yeah work is fine, started last week, all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>1</td>\n",
       "      <td>WIN: We have a winner! Mr. T. Foley won an iPo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>Where are you?when wil you reach here?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>1</td>\n",
       "      <td>Do you want a new Video handset? 750 any time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4678</th>\n",
       "      <td>0</td>\n",
       "      <td>Wewa is 130. Iriver 255. All 128 mb.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>1</td>\n",
       "      <td>You have 1 new message. Please call 08718738034.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e56a1e78-22c6-469d-b950-644958e4a84b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e56a1e78-22c6-469d-b950-644958e4a84b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e56a1e78-22c6-469d-b950-644958e4a84b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-e05c5c43-0156-480a-95f5-2f7972d41c55\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e05c5c43-0156-480a-95f5-2f7972d41c55')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-e05c5c43-0156-480a-95f5-2f7972d41c55 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"                   random_state=211)\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Thank you. do you generally date the brothas?\",\n          \"Yeah work is fine, started last week, all the same stuff as before, dull but easy and guys are fun!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "balanced_df.sample(frac=0.005, random_state=211).reset_index(drop=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "6JEC7o9cbi-0",
    "outputId": "bc9d5f08-46cf-4ace-bff3-d0d31bd5eca1"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Label                                               Text\n",
       "0      0      Thank you. do you generally date the brothas?\n",
       "1      0  Yeah work is fine, started last week, all the ...\n",
       "2      1  WIN: We have a winner! Mr. T. Foley won an iPo...\n",
       "3      0             Where are you?when wil you reach here?\n",
       "4      1  Do you want a new Video handset? 750 any time ...\n",
       "5      0               Wewa is 130. Iriver 255. All 128 mb.\n",
       "6      1   You have 1 new message. Please call 08718738034."
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-0764c0fd-661e-49ec-9657-c100619f832e\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Yeah work is fine, started last week, all the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>WIN: We have a winner! Mr. T. Foley won an iPo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Where are you?when wil you reach here?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Do you want a new Video handset? 750 any time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Wewa is 130. Iriver 255. All 128 mb.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>You have 1 new message. Please call 08718738034.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0764c0fd-661e-49ec-9657-c100619f832e')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0764c0fd-661e-49ec-9657-c100619f832e button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0764c0fd-661e-49ec-9657-c100619f832e');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-749f0e91-22d0-4b92-9fb3-fe3fc249b25b\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-749f0e91-22d0-4b92-9fb3-fe3fc249b25b')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-749f0e91-22d0-4b92-9fb3-fe3fc249b25b button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "summary": "{\n  \"name\": \"balanced_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Thank you. do you generally date the brothas?\",\n          \"Yeah work is fine, started last week, all the same stuff as before, dull but easy and guys are fun!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "\n",
    "  # shuffle dataset\n",
    "  df = df.sample(frac=1, random_state=211).reset_index(drop=True)\n",
    "\n",
    "  # compute split range\n",
    "  train_end = int(len(df) * train_frac)\n",
    "  validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "  # split\n",
    "  train_df = df[:train_end]\n",
    "  validation_df = df[train_end:validation_end]\n",
    "  test_df = df[validation_end:]\n",
    "\n",
    "  return train_df, validation_df, test_df\n",
    "\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "\n",
    "# save splitted dataframe into csv files\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ],
   "metadata": {
    "id": "7CwbnrKmar7n"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Create DataLoaders"
   ],
   "metadata": {
    "id": "dI5VEf5EhdTb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- But first, let's create a custom dataset:\n",
    "1. We need a tokenizer\n",
    "2. treat each line of the original raw dataset (aka `\"Text\"` column) as sequence of tokens\n",
    "3. we should pad special tokens (aka `\"<|endoftext|>\"`) to every sequence so that it matches with the longest sequence or pre-defined `sequence length`"
   ],
   "metadata": {
    "id": "YhWGADM7hg67"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n",
    "print(tokenizer.decode([50256]))\n",
    "print(tokenizer.n_vocab)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxGTL-NZg4tX",
    "outputId": "0a4368e6-ef20-41af-9186-8f9352965dba"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[50256]\n",
      "<|endoftext|>\n",
      "50257\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "  def __init__(self,\n",
    "               csv_file,\n",
    "               tokenizer,\n",
    "               max_length=None,\n",
    "               pad_token_id=50256):\n",
    "    self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    # pre-tokenizer texts\n",
    "    self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "\n",
    "    if max_length is None:\n",
    "      self.max_length = self._longest_encoded_length()\n",
    "    else:\n",
    "      self.max_length = max_length\n",
    "      # truncate sequences if they're longer than max_length\n",
    "      self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
    "\n",
    "    # pad tokens\n",
    "    self.encoded_texts = [\n",
    "        encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "        for encoded_text in self.encoded_texts\n",
    "    ]\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    encoded_sequence = self.encoded_texts[index]\n",
    "    label = self.data.iloc[index][\"Label\"]\n",
    "    return (\n",
    "        torch.tensor(encoded_sequence, dtype=torch.long),\n",
    "        torch.tensor(label, dtype=torch.long)\n",
    "    )\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def _longest_encoded_length(self):\n",
    "    return max(len(encoded_text) for encoded_text in self.encoded_texts)"
   ],
   "metadata": {
    "id": "N3AbqSKcg_OR"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's create our Datasets!!!"
   ],
   "metadata": {
    "id": "hUx9n863rTlO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)\n",
    "\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GA62PJwSqkr5",
    "outputId": "499dfd1f-e16e-46a4-92b3-5c5b382fbe7e"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "120\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Now create DataLoaders:"
   ],
   "metadata": {
    "id": "dvDm6GZArZOq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(211)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ],
   "metadata": {
    "id": "eiki1pBFq8KV"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jz8xF2eDr-_O",
    "outputId": "2764fd68-9989-45ab-ca18-81e5f4037e48"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UiYVLlY_sDVE",
    "outputId": "aecad709-c305-4064-897b-fd6381696e47"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Initializing a model with pretrained weights"
   ],
   "metadata": {
    "id": "ldmZ1tR6sO8D"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's reuse the code from the previous experiments:"
   ],
   "metadata": {
    "id": "cprS0YxEsu49"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ],
   "metadata": {
    "id": "qT-XfrsAsIRl"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2O4zR9ctGD2",
    "outputId": "967a53ec-fd49-4dd2-9bf1-2d8ef6d867da"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x7cb2728314d0>)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_embedding_dim,\n",
    "                 output_embedding_dim,\n",
    "                 context_length,\n",
    "                 dropout,\n",
    "                 num_heads,\n",
    "                 qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (output_embedding_dim % num_heads == 0), \\\n",
    "            \"output_embedding_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.output_embedding_dim = output_embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = output_embedding_dim // num_heads\n",
    "        self.W_query = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
    "                                 bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
    "                               bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
    "                                 bias=qkv_bias)\n",
    "        self.output_projection = nn.Linear(output_embedding_dim,\n",
    "                                           output_embedding_dim)  # to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch, num_tokens, input_embedding_dim = inputs.shape\n",
    "\n",
    "        # qkv shapes : (batch, num_tokens, output_embedding_dim)\n",
    "        keys = self.W_key(inputs)\n",
    "        values = self.W_value(inputs)\n",
    "        queries = self.W_query(inputs)\n",
    "\n",
    "        # qkv shapes : (batch, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # qkv shapes : (batch, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "\n",
    "        # compute attention scores for each head\n",
    "        attention_scores = queries @ keys.transpose(3, 2)\n",
    "        attention_scores.masked_fill_(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], - torch.inf)\n",
    "\n",
    "        # compute attention weights + dropout\n",
    "        masked_attention_weight = torch.softmax(\n",
    "            attention_scores / (keys.shape[-1] ** 0.5),\n",
    "            dim=-1)\n",
    "        masked_attention_dropout_weight = self.dropout(masked_attention_weight)\n",
    "\n",
    "        # compute context vectors\n",
    "        # shape : (batch, num_tokens, num_heads, head_dim)\n",
    "        context_vector = (masked_attention_dropout_weight @ values).transpose(1, 2)\n",
    "\n",
    "        # combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        # shape : (batch, num_tokens, output_embedding_dim)\n",
    "        context_vector = context_vector.contiguous().view(\n",
    "            batch, num_tokens, self.output_embedding_dim)\n",
    "\n",
    "        # linear projection (optional)\n",
    "        context_vector = self.output_projection(context_vector)\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.epsilon = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1,\n",
    "                    unbiased=False,  # Bessel's correction (n-1)\n",
    "                    keepdim=True)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.epsilon)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config[\"emb_dim\"],  # 768\n",
    "                      4 * config[\"emb_dim\"]),  # 3072\n",
    "            GELU(),  # 3072\n",
    "            nn.Linear(4 * config[\"emb_dim\"],  # 3072\n",
    "                      config[\"emb_dim\"])  # 768\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(input_embedding_dim=config[\"emb_dim\"],\n",
    "                                            output_embedding_dim=config[\"emb_dim\"],\n",
    "                                            context_length=config[\"context_length\"],\n",
    "                                            dropout=config[\"drop_rate\"],\n",
    "                                            num_heads=config[\"n_heads\"],\n",
    "                                            qkv_bias=config[\"qkv_bias\"])\n",
    "        self.feed_forward = FeedForward(config)\n",
    "        self.layer_norm1 = LayerNorm(config[\"emb_dim\"])\n",
    "        self.layer_norm2 = LayerNorm(config[\"emb_dim\"])\n",
    "        self.drop_skip = nn.Dropout(config[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # skip connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.attention(x)  # shape: [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_skip(x)\n",
    "        x = shortcut + x  # skip connection\n",
    "\n",
    "        # skip connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = self.drop_skip(x)\n",
    "        x = shortcut + x  # skip connection\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPT2Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(config[\"vocab_size\"],\n",
    "                                      config[\"emb_dim\"])\n",
    "        self.position_emb = nn.Embedding(config[\"context_length\"],\n",
    "                                         config[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(config[\"drop_rate\"])\n",
    "\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(config) for _ in range(config[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(config[\"emb_dim\"])\n",
    "\n",
    "        self.out_head = nn.Linear(config[\"emb_dim\"],\n",
    "                                  config[\"vocab_size\"],\n",
    "                                  bias=False)\n",
    "\n",
    "    def forward(self, input_token):\n",
    "        batch_size, sequence_length = input_token.shape\n",
    "        token_embeds = self.token_emb(input_token)\n",
    "        position_embeds = self.position_emb(\n",
    "            torch.arange(sequence_length,\n",
    "                         device=input_token.device))\n",
    "        embeds = token_embeds + position_embeds\n",
    "        x = self.drop_emb(embeds)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.position_emb.weight = assign(gpt.position_emb.weight, params['wpe'])\n",
    "    gpt.token_emb.weight = assign(gpt.token_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.transformer_blocks[b].attention.W_query.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_query.weight, q_w.T)\n",
    "        gpt.transformer_blocks[b].attention.W_key.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_key.weight, k_w.T)\n",
    "        gpt.transformer_blocks[b].attention.W_value.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.transformer_blocks[b].attention.W_query.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_query.bias, q_b)\n",
    "        gpt.transformer_blocks[b].attention.W_key.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_key.bias, k_b)\n",
    "        gpt.transformer_blocks[b].attention.W_value.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_value.bias, v_b)\n",
    "\n",
    "        gpt.transformer_blocks[b].attention.output_projection.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.output_projection.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformer_blocks[b].attention.output_projection.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.output_projection.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transformer_blocks[b].feed_forward.layers[0].weight = assign(\n",
    "            gpt.transformer_blocks[b].feed_forward.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.transformer_blocks[b].feed_forward.layers[0].bias = assign(\n",
    "            gpt.transformer_blocks[b].feed_forward.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.transformer_blocks[b].feed_forward.layers[2].weight = assign(\n",
    "            gpt.transformer_blocks[b].feed_forward.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformer_blocks[b].feed_forward.layers[2].bias = assign(\n",
    "            gpt.transformer_blocks[b].feed_forward.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transformer_blocks[b].layer_norm1.scale = assign(\n",
    "            gpt.transformer_blocks[b].layer_norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.transformer_blocks[b].layer_norm1.shift = assign(\n",
    "            gpt.transformer_blocks[b].layer_norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.transformer_blocks[b].layer_norm2.scale = assign(\n",
    "            gpt.transformer_blocks[b].layer_norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.transformer_blocks[b].layer_norm2.shift = assign(\n",
    "            gpt.transformer_blocks[b].layer_norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ],
   "metadata": {
    "id": "Tn4DFaAguVCG"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "model_size"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "lXIqfZesvE1c",
    "outputId": "567aba62-570c-45c6-f653-7ddb4eaa2162"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'124M'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "print(settings)\n",
    "print(params.keys())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRibV0axvJLr",
    "outputId": "365b04ba-5442-4f8b-cbd8-160610375bf4"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n",
      "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = GPT2Model(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ],
   "metadata": {
    "id": "wU3U7PuOvTO3"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's check whether the model generates coherent text:"
   ],
   "metadata": {
    "id": "lJ53X0mCwH_p"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "  # turn the list of token IDs into tensor with batch dimension\n",
    "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "  return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(encoded_tensor, tokenizer):\n",
    "  # turn tensor without batch dimension to list\n",
    "  token_ids = encoded_tensor.squeeze(0).tolist()\n",
    "  text = tokenizer.decode(token_ids)\n",
    "  return text\n",
    "\n",
    "\n",
    "def generate_text(model,\n",
    "                  input_batch,\n",
    "                  max_new_tokens,\n",
    "                  context_size,\n",
    "                  temperature=0.0,\n",
    "                  top_k=None,\n",
    "                  eos_id=None):\n",
    "  for _ in range(max_new_tokens):\n",
    "    # crop current context if it exceeds the supported context_size\n",
    "    crop_input_batch = input_batch[:, -context_size:]\n",
    "\n",
    "    # predict next token\n",
    "    with torch.no_grad():\n",
    "      logits = model(crop_input_batch)\n",
    "\n",
    "    # consider only logits of the last token\n",
    "    logits = logits[:, -1, :] # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
    "\n",
    "    # NEW: filter logits with top_k sampling\n",
    "    if top_k is not None:\n",
    "      # keep only top_k values\n",
    "      top_logits, _ = torch.topk(logits, top_k)\n",
    "      min_val = top_logits[:, -1] # min value among the top_k values\n",
    "      # all values other than top_k values will be set to -inf\n",
    "      logits = torch.where(logits < min_val,\n",
    "                           torch.tensor(-torch.inf).to(logits.device),\n",
    "                           logits)\n",
    "\n",
    "    # NEW: temperature scaling\n",
    "    if temperature > 0.0:\n",
    "      logits = logits / temperature\n",
    "\n",
    "      probas = torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
    "      predicted_tokens = torch.multinomial(probas, num_samples=1) # (batch, 1)\n",
    "\n",
    "    else: # same as before\n",
    "      #probas = torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
    "      predicted_tokens = torch.argmax(logits, dim=-1, keepdim=True) # (batch, 1)\n",
    "\n",
    "    if predicted_tokens == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "    # update input_batch (append predicted tokens to the sequences)\n",
    "    input_batch = torch.cat([input_batch, predicted_tokens], dim=1) # [batch, num_tokens+1]\n",
    "\n",
    "  return input_batch"
   ],
   "metadata": {
    "id": "GTCm3BByvvju"
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_1 = \"In the midst of winter\"\n",
    "\n",
    "token_ids = generate_text(\n",
    "    model=model,\n",
    "    input_batch=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    temperature = 2.0,\n",
    "    top_k = 10\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejkpoLYlw6gM",
    "outputId": "7689ab71-c600-4c69-b95a-dfe6d1e287c5"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In the midst of winter break I was sitting with two friends who I would call friends and would say 'I love you so so much. It's been really nice to see that you guys care.' It's been really nice for the rest of us.\" She's not exactly\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "source": [
    "- before finetuning, let's see whether the model can classify spam messages via prompting:"
   ],
   "metadata": {
    "id": "aSfkozntxq1t"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text(\n",
    "    model=model,\n",
    "    input_batch=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnPpUebPxVNP",
    "outputId": "48dba05d-10fb-4cae-a55b-47eb38e20376"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Adding a classification head"
   ],
   "metadata": {
    "id": "0BLzwF-gyJv8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5DoN51Ux_QS",
    "outputId": "736e811b-c7be-4f0c-c665-a8f6fb04af62"
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPT2Model(\n",
      "  (token_emb): Embedding(50257, 768)\n",
      "  (position_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (transformer_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (output_projection): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm1): LayerNorm()\n",
      "      (layer_norm2): LayerNorm()\n",
      "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torchinfo"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JXuj95yeeagD",
    "outputId": "e14bf8f4-1541-440d-bc64-144b8f6065bc"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(1, BASE_CONFIG[\"context_length\"]),      # (batch, seq_len)\n",
    "    dtypes=[torch.long],                                # token IDs are int64\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n",
    "    row_settings=(\"depth\", \"var_names\"),                # valid row options\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsyEcxZ62MQk",
    "outputId": "388889e3-b795-4403-9af9-05a175eac213"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                       Input Shape               Output Shape              Param #                   Trainable\n",
       "===========================================================================================================================================================\n",
       "GPT2Model (GPT2Model)                                   [1, 1024]                 [1, 1024, 50257]          --                        True\n",
       "├─Embedding (token_emb): 1-1                            [1, 1024]                 [1, 1024, 768]            38,597,376                True\n",
       "├─Embedding (position_emb): 1-2                         [1024]                    [1024, 768]               786,432                   True\n",
       "├─Dropout (drop_emb): 1-3                               [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "├─Sequential (transformer_blocks): 1-4                  [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    └─TransformerBlock (0): 2-1                        [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-1                [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-2         [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-3                    [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-4                [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-5             [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-6                    [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (1): 2-2                        [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-7                [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-8         [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-9                    [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-10               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-11            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-12                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (2): 2-3                        [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-13               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-14        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-15                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-16               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-17            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-18                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (3): 2-4                        [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-19               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-20        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-21                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-22               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-23            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-24                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (4): 2-5                        [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-25               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-26        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-27                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-28               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-29            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-30                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (5): 2-6                        [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-31               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-32        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-33                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-34               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-35            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-36                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (6): 2-7                        [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-37               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-38        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-39                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-40               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-41            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-42                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (7): 2-8                        [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-43               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-44        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-45                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-46               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-47            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-48                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (8): 2-9                        [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-49               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-50        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-51                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-52               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-53            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-54                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (9): 2-10                       [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-55               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-56        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-57                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-58               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-59            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-60                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (10): 2-11                      [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-61               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-62        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-63                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-64               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-65            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-66                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (11): 2-12                      [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-67               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-68        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-69                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-70               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-71            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-72                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "├─LayerNorm (final_norm): 1-5                           [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "├─Linear (out_head): 1-6                                [1, 1024, 768]            [1, 1024, 50257]          38,597,376                True\n",
       "===========================================================================================================================================================\n",
       "Total params: 163,037,184\n",
       "Trainable params: 163,037,184\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 967.52\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1261.05\n",
       "Params size (MB): 652.15\n",
       "Estimated Total Size (MB): 1913.21\n",
       "==========================================================================================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- first, freeze all parameters:"
   ],
   "metadata": {
    "id": "veQh06-uyXUr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "id": "P4lUOqEvyUPE"
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- and change the output layer `out_head` into `(out_head): Linear(in_features=768, out_features=2, bias=False)`"
   ],
   "metadata": {
    "id": "JqhfrIh0ygfc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(211)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ],
   "metadata": {
    "id": "097Joa2ZycQc"
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- we make the last transformer block and the final LayerNorm module connecting the last transformer block to the output layer trainable:"
   ],
   "metadata": {
    "id": "FehlEfzJwEEp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for param in model.transformer_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "id": "MktJGWrlwAyE"
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install torchinfo"
   ],
   "metadata": {
    "id": "vdJC7cIu0Adz"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(1, BASE_CONFIG[\"context_length\"]),      # (batch, seq_len)\n",
    "    dtypes=[torch.long],                                # token IDs are int64\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\", \"trainable\"),\n",
    "    row_settings=(\"depth\", \"var_names\"),                # valid row options\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wtbw1uWnzQix",
    "outputId": "ecd8390d-e690-4721-a43b-304836c30c35"
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type (var_name):depth-idx)                       Input Shape               Output Shape              Param #                   Trainable\n",
       "===========================================================================================================================================================\n",
       "GPT2Model (GPT2Model)                                   [1, 1024]                 [1, 1024, 2]              --                        Partial\n",
       "├─Embedding (token_emb): 1-1                            [1, 1024]                 [1, 1024, 768]            (38,597,376)              False\n",
       "├─Embedding (position_emb): 1-2                         [1024]                    [1024, 768]               (786,432)                 False\n",
       "├─Dropout (drop_emb): 1-3                               [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "├─Sequential (transformer_blocks): 1-4                  [1, 1024, 768]            [1, 1024, 768]            --                        Partial\n",
       "│    └─TransformerBlock (0): 2-1                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-1                [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-2         [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-3                    [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-4                [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-5             [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-6                    [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (1): 2-2                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-7                [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-8         [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-9                    [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-10               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-11            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-12                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (2): 2-3                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-13               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-14        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-15                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-16               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-17            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-18                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (3): 2-4                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-19               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-20        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-21                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-22               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-23            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-24                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (4): 2-5                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-25               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-26        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-27                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-28               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-29            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-30                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (5): 2-6                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-31               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-32        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-33                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-34               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-35            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-36                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (6): 2-7                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-37               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-38        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-39                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-40               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-41            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-42                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (7): 2-8                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-43               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-44        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-45                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-46               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-47            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-48                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (8): 2-9                        [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-49               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-50        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-51                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-52               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-53            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-54                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (9): 2-10                       [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-55               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-56        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-57                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-58               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-59            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-60                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (10): 2-11                      [1, 1024, 768]            [1, 1024, 768]            --                        False\n",
       "│    │    └─LayerNorm (layer_norm1): 3-61               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─MultiHeadAttention (attention): 3-62        [1, 1024, 768]            [1, 1024, 768]            (2,362,368)               False\n",
       "│    │    └─Dropout (drop_skip): 3-63                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-64               [1, 1024, 768]            [1, 1024, 768]            (1,536)                   False\n",
       "│    │    └─FeedForward (feed_forward): 3-65            [1, 1024, 768]            [1, 1024, 768]            (4,722,432)               False\n",
       "│    │    └─Dropout (drop_skip): 3-66                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    └─TransformerBlock (11): 2-12                      [1, 1024, 768]            [1, 1024, 768]            --                        True\n",
       "│    │    └─LayerNorm (layer_norm1): 3-67               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─MultiHeadAttention (attention): 3-68        [1, 1024, 768]            [1, 1024, 768]            2,362,368                 True\n",
       "│    │    └─Dropout (drop_skip): 3-69                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "│    │    └─LayerNorm (layer_norm2): 3-70               [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "│    │    └─FeedForward (feed_forward): 3-71            [1, 1024, 768]            [1, 1024, 768]            4,722,432                 True\n",
       "│    │    └─Dropout (drop_skip): 3-72                   [1, 1024, 768]            [1, 1024, 768]            --                        --\n",
       "├─LayerNorm (final_norm): 1-5                           [1, 1024, 768]            [1, 1024, 768]            1,536                     True\n",
       "├─Linear (out_head): 1-6                                [1, 1024, 768]            [1, 1024, 2]              1,538                     True\n",
       "===========================================================================================================================================================\n",
       "Total params: 124,441,346\n",
       "Trainable params: 7,090,946\n",
       "Non-trainable params: 117,350,400\n",
       "Total mult-adds (Units.MEGABYTES): 928.92\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 849.36\n",
       "Params size (MB): 497.77\n",
       "Estimated Total Size (MB): 1347.14\n",
       "==========================================================================================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see what has changed:"
   ],
   "metadata": {
    "id": "TOqJFLcY26Am"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode(\"I open myself to\")\n",
    "inputs = torch.tensor(inputs, dtype=torch.long).unsqueeze(0).to(device)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnODKUy8z-4M",
    "outputId": "1c5757e5-9f15-483a-cf32-6af63c999f83"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inputs: tensor([[  40, 1280, 3589,  284]], device='cuda:0')\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aoD8GfM13EqW",
    "outputId": "13ffe88e-9ef4-4c58-f905-f506f3581756"
   },
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Outputs:\n",
      " tensor([[[-0.2085,  1.4101],\n",
      "         [-0.9657,  5.2382],\n",
      "         [ 0.1119,  4.5591],\n",
      "         [ 0.3584,  5.9848]]], device='cuda:0')\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Uf_5xzK3Kqb",
    "outputId": "669b1b27-5d24-4d42-b477-f90d1686fb30"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Last output token: tensor([[0.3584, 5.9848]], device='cuda:0')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Calculating the classification loss and accuracy"
   ],
   "metadata": {
    "id": "K--aY3iT3Zyu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4J2DkjW3SgS",
    "outputId": "36e5a933-02df-4c76-ed78-53e42bf6b142"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Last output token: tensor([[0.3584, 5.9848]], device='cuda:0')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRhQCx3X3jFW",
    "outputId": "f3a1dda8-3964-45e1-8239-ae356902b0f3"
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class label: 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- since `softmax` is optional, we can also do:"
   ],
   "metadata": {
    "id": "-kz7Pnfj3r5J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLKJ9Yob3m8u",
    "outputId": "a7358c6d-e2d6-4c19-98f4-6bb1a6d34457"
   },
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class label: 1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's create a classification accuracy function for the (pretrained or finetuned) model over the pre-defined number of batches in the dataloader:"
   ],
   "metadata": {
    "id": "c50sKk4MbgST"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def calc_accuracy_loader(data_loader,\n",
    "                         model,\n",
    "                         device,\n",
    "                         num_batches=None):\n",
    "  model.eval()\n",
    "  correct_predictions, num_examples = 0, 0\n",
    "\n",
    "  if num_batches is None:\n",
    "    num_batches = len(data_loader)\n",
    "  else:\n",
    "    num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "  for batch_id, (input_batch, label_batch) in enumerate(data_loader):\n",
    "    if batch_id < num_batches:\n",
    "      input_batch, label_batch = input_batch.to(device), label_batch.to(device)\n",
    "\n",
    "      with torch.no_grad():\n",
    "        logits = model(input_batch)[:, -1, :] # logits of the last output token\n",
    "      predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "      num_examples += predicted_labels.shape[0]\n",
    "      correct_predictions += (predicted_labels == label_batch).sum().item()\n",
    "    else:\n",
    "      break\n",
    "  return correct_predictions / num_examples"
   ],
   "metadata": {
    "id": "XWb3pNoz3x2_"
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkwvLuZifjo0",
    "outputId": "2308734a-f9ff-4698-c87a-e744598fc963"
   },
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(211)\n",
    "\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGT0X29sdwvE",
    "outputId": "8b7a88c5-b13e-48a6-afd0-7a332cde41d0"
   },
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 51.25%\n",
      "Validation accuracy: 58.75%\n",
      "Test accuracy: 37.50%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- next, we define the cross-entropy loss function as a proxy for maximizing the classification accuracy for the (pretrained or finetuned) model over the pre-defined number of batches in the dataloader.\n",
    "\n",
    "But first, let's calculate loss for each batch:"
   ],
   "metadata": {
    "id": "WGWqGQAqgMIV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def calc_loss_batch(input_batch,\n",
    "                    label_batch,\n",
    "                    model,\n",
    "                    device):\n",
    "  input_batch, label_batch = input_batch.to(device), label_batch.to(device)\n",
    "  logits = model(input_batch)[:, -1, :] # logits of the last output token\n",
    "  loss = torch.nn.functional.cross_entropy(logits, label_batch)\n",
    "  return loss"
   ],
   "metadata": {
    "id": "k0QT4x67gJrD"
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# same as pretraining\n",
    "def calc_loss_loader(data_loader,\n",
    "                     model,\n",
    "                     device,\n",
    "                     num_batches=None):\n",
    "  total_loss = 0.0\n",
    "  if len(data_loader) == 0:\n",
    "    return float(\"nan\")\n",
    "  elif num_batches is None:\n",
    "    num_batches = len(data_loader)\n",
    "  else:\n",
    "    num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "  for batch_id, (input_batch, label_batch) in enumerate(data_loader):\n",
    "    if batch_id < num_batches:\n",
    "      loss = calc_loss_batch(input_batch, label_batch, model, device)\n",
    "      total_loss += loss.item()\n",
    "    else:\n",
    "      break\n",
    "  return total_loss / num_batches"
   ],
   "metadata": {
    "id": "SbdsNZsjeD-k"
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdSCs3KjjAFp",
    "outputId": "5a7da87c-605b-4631-c35b-d7853d6f6979"
   },
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss: 1.851\n",
      "Validation loss: 1.299\n",
      "Test loss: 1.851\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Finetuning the model on supervised data"
   ],
   "metadata": {
    "id": "QorJHszHjKKj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- The `train_classifier_simple` function is the same as the `train_model_simple` function we used for pretraining the model.\n",
    "- The only differences are:\n",
    "  1. we track the number of training `examples_seen` instead of the number of tokens seen\n",
    "  2. calculate the accuracy after each epoch instead of printing a sample text after each epoch"
   ],
   "metadata": {
    "id": "vGe5c12XjhAm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train_classifier_simple(model,\n",
    "                            train_loader,\n",
    "                            val_loader,\n",
    "                            optimizer,\n",
    "                            device,\n",
    "                            num_epochs,\n",
    "                            eval_freq,\n",
    "                            eval_iter # number of batches to evaluate from\n",
    "                            ):\n",
    "  train_losses, val_losses = [], []\n",
    "  train_accuracies, val_accuracies = [], []\n",
    "  examples_seen, global_step = 0, -1\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for input_batch, label_batch in train_loader:\n",
    "      optimizer.zero_grad()\n",
    "      loss = calc_loss_batch(input_batch, label_batch, model, device)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "      global_step += 1\n",
    "\n",
    "\n",
    "      # optional evaluation step\n",
    "      if global_step % eval_freq == 0:\n",
    "        train_loss, val_loss = evaluate_model(model,\n",
    "                                              train_loader,\n",
    "                                              val_loader,\n",
    "                                              device,\n",
    "                                              eval_iter)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "    # calculate accuracy after each epoch\n",
    "    train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "    val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "    print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "  return train_losses, val_losses, train_accuracies, val_accuracies, examples_seen"
   ],
   "metadata": {
    "id": "Tux6pIw3jGJI"
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# same as pretraining\n",
    "def evaluate_model(model,\n",
    "                   train_loader,\n",
    "                   val_loader,\n",
    "                   device,\n",
    "                   eval_iter):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "  model.train()\n",
    "  return train_loss, val_loss"
   ],
   "metadata": {
    "id": "45orFD-cmISX"
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(211)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i4qBiONmYtl",
    "outputId": "9da0ca74-cf3b-4fa1-88f2-1e82abae83a6"
   },
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.530, Val loss 1.177\n",
      "Ep 1 (Step 000050): Train loss 0.637, Val loss 0.639\n",
      "Ep 1 (Step 000100): Train loss 0.522, Val loss 0.533\n",
      "Training accuracy: 80.00% | Validation accuracy: 87.50%\n",
      "Ep 2 (Step 000150): Train loss 0.412, Val loss 0.336\n",
      "Ep 2 (Step 000200): Train loss 0.224, Val loss 0.106\n",
      "Ep 2 (Step 000250): Train loss 0.028, Val loss 0.070\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 3 (Step 000300): Train loss 0.124, Val loss 0.076\n",
      "Ep 3 (Step 000350): Train loss 0.124, Val loss 0.048\n",
      "Training accuracy: 97.50% | Validation accuracy: 100.00%\n",
      "Ep 4 (Step 000400): Train loss 0.075, Val loss 0.037\n",
      "Ep 4 (Step 000450): Train loss 0.194, Val loss 0.043\n",
      "Ep 4 (Step 000500): Train loss 0.171, Val loss 0.041\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.045, Val loss 0.037\n",
      "Ep 5 (Step 000600): Train loss 0.021, Val loss 0.035\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 6 (Step 000650): Train loss 0.022, Val loss 0.036\n",
      "Ep 6 (Step 000700): Train loss 0.053, Val loss 0.031\n",
      "Ep 6 (Step 000750): Train loss 0.026, Val loss 0.037\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 7 (Step 000800): Train loss 0.217, Val loss 0.029\n",
      "Ep 7 (Step 000850): Train loss 0.005, Val loss 0.027\n",
      "Ep 7 (Step 000900): Train loss 0.123, Val loss 0.037\n",
      "Training accuracy: 100.00% | Validation accuracy: 100.00%\n",
      "Ep 8 (Step 000950): Train loss 0.010, Val loss 0.027\n",
      "Ep 8 (Step 001000): Train loss 0.025, Val loss 0.024\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 9 (Step 001050): Train loss 0.015, Val loss 0.026\n",
      "Ep 9 (Step 001100): Train loss 0.008, Val loss 0.050\n",
      "Ep 9 (Step 001150): Train loss 0.125, Val loss 0.036\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 10 (Step 001200): Train loss 0.021, Val loss 0.023\n",
      "Ep 10 (Step 001250): Train loss 0.006, Val loss 0.056\n",
      "Training accuracy: 95.00% | Validation accuracy: 100.00%\n",
      "Training completed in 0.53 minutes.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- let's plot the loss function for the training and validation set:"
   ],
   "metadata": {
    "id": "LqjmVVnRmg6G"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "plden2UZmeXy"
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "v0uSfpgVmohE",
    "outputId": "f67440e4-e0a6-4ef8-9ec0-82e833c438c7"
   },
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's plot the accuracy:"
   ],
   "metadata": {
    "id": "BTZ3NDKWw9sm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "N-5z_MK1mq9r",
    "outputId": "097f7b09-ab27-4a85-b350-7754f8f9912c"
   },
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- let's compute the training, validation, and test set performances over the complete dataset:"
   ],
   "metadata": {
    "id": "IypbP7l-xY6V"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ombuMpJfsfli",
    "outputId": "afca918a-dda0-4b75-9547-9a236d11edf5"
   },
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training accuracy: 98.46%\n",
      "Validation accuracy: 95.97%\n",
      "Test accuracy: 96.33%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. Using the LLM as a spam classifier"
   ],
   "metadata": {
    "id": "WSi4MzHQx7UE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- let's create a function the uses our finetuned model to make prediction on the spam dataset:"
   ],
   "metadata": {
    "id": "zlUp-4aQyPAd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def classify_review(text,\n",
    "                    model,\n",
    "                    tokenizer,\n",
    "                    device,\n",
    "                    max_length=None,\n",
    "                    pad_token_id=50256):\n",
    "  model.eval()\n",
    "\n",
    "  # input preprocessing\n",
    "  input_ids = tokenizer.encode(text)\n",
    "  supported_context_length = model.position_emb.weight.shape[0]\n",
    "  input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "  input_ids += [pad_token_id] * (max_length  - len(input_ids))\n",
    "  input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "\n",
    "  # model inference\n",
    "  with torch.no_grad():\n",
    "    logits = model(input_tensor)[:, -1, :] # logits of the last output token\n",
    "  predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "  # return the classifier result\n",
    "  return \"spam\" if predicted_label == 1 else \"not spam\""
   ],
   "metadata": {
    "id": "rc_TEnZQsfip"
   },
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1UqgJIizzj9B",
    "outputId": "f884667e-9511-44cb-b17e-bfdfdb842c43"
   },
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "spam\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FzdM7mcyzj3Z",
    "outputId": "9399efd9-daea-4ae4-cefc-dace3245c403"
   },
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "not spam\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's save the model:"
   ],
   "metadata": {
    "id": "jmWOC4k6zvbn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ],
   "metadata": {
    "id": "yaE1wIdazvMT"
   },
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "and load it in another session:"
   ],
   "metadata": {
    "id": "d1GeJkWMz2G8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zcyuw69izvJX",
    "outputId": "93d2550f-3284-40c9-dd30-ece0c5c19794"
   },
   "execution_count": 58,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Kz2i24xgzjDx"
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "notebook_end_time = time.time()\n",
    "runtime_in_seconds = notebook_end_time - notebook_start_time\n",
    "\n",
    "# format as minutes and seconds\n",
    "minutes, seconds = divmod(runtime_in_seconds, 60)\n",
    "print(f\"Notebook runtime: {int(minutes)} min {seconds:.2f} sec\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22EIm8X3sfdy",
    "outputId": "343825f7-1be5-4aa8-a91d-12bded04cef5"
   },
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Notebook runtime: 0 min 56.81 sec\n"
     ]
    }
   ]
  }
 ]
}
