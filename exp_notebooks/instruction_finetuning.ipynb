{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1lP1z53h69QO"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "notebook_start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "id": "KWFEbEoZ7_k6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KdoKchF7-_q",
    "outputId": "7250b8d5-e38e-42f2-e93c-6de459933e7b"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numpy version: 2.0.2\n",
      "matplotlib version: 3.10.0\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.6.0+cu124\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.18.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Dataset downloading and formatting"
   ],
   "metadata": {
    "id": "rbRS8fEFKsHr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    # The book originally contained this unnecessary \"else\" clause:\n",
    "    #else:\n",
    "    #    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    #        text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQcbNOeD7-9y",
    "outputId": "81fff4e4-f340-4405-f5af-0ab378ca8cbd"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6hLK6ZM7-6Y",
    "outputId": "745018b2-caa0-485d-af43-1fee182c73cf"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Another example entry:\\n\", data[999])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2YVIajf7-3N",
    "outputId": "8c638668-962c-4e71-b0b0-931d8aabc085"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- we use Alpaca-style prompt formatting, which was the original prompt template for instruction finetuning\n",
    "- we format the input that we will pass as input to the LLM"
   ],
   "metadata": {
    "id": "Rsaraq_yLGTM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ],
   "metadata": {
    "id": "cUGe9iq17-1G"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "A formatted response with input field looks like as shown below"
   ],
   "metadata": {
    "id": "Sjf5F2xKLT6A"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qjVXZH-67-yn",
    "outputId": "61bd380a-57cf-4e04-c16f-ce2406bd26be"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWv-bgSQ7-wJ",
    "outputId": "234a6069-f6a2-4c87-ed0f-03cab99b3149"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Organizing data into training batches"
   ],
   "metadata": {
    "id": "c_wr_4LGLpEO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- first, let's split the dataset:"
   ],
   "metadata": {
    "id": "mi1SXZYcL5Mb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgFJUvQp7-tx",
    "outputId": "82d283f2-e3c6-4494-ff6f-bd871ac01983"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's implement `InstructionDataset` class that pre-tokenizes all inputs in the dataset, similar to the `SpamDataset` class in classification finetuning:"
   ],
   "metadata": {
    "id": "S2w5wyHgMRR3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "  def __init__(self, data, tokenizer):\n",
    "    self.data = data\n",
    "\n",
    "    # pre-tokenizer texts\n",
    "    self.encoded_texts = []\n",
    "    for entry in data:\n",
    "      instruction_plus_input = format_input(entry)\n",
    "      response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "      full_text = instruction_plus_input + response_text\n",
    "      self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.encoded_texts[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ],
   "metadata": {
    "id": "T0uVn3y87-rL"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- now use the <|endoftext|> token as a padding token and pad all inputs in a batch to a similar length (not the entire dataset)\n",
    "- to do that, we custom \"collate\" function that can pass to the data loader\n",
    "- This custom collate function pads the training examples in each batch to have the same length (but different batches can have different lengths)"
   ],
   "metadata": {
    "id": "Nf7dMzOpFWtY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0rvN06KFUHn",
    "outputId": "7b5fda59-22bc-445f-f0dc-444a7f21a02b"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[50256]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_1(batch,\n",
    "                           pad_token_id=50256,\n",
    "                           device=\"cpu\"):\n",
    "  # find the longest sequence in the batch and increase max_length\n",
    "  # by +1 for the padding token, which indicates the end of sequence/answer\n",
    "  batch_max_length = max(len(item) + 1 for item in batch)\n",
    "\n",
    "  # pad and prepare inputs\n",
    "  inputs_lst = []\n",
    "\n",
    "  for item in batch:\n",
    "    new_item = item.copy()\n",
    "    # Add an <|endoftext|> token\n",
    "    new_item += [pad_token_id]\n",
    "    # Pad sequences to batch_max_length\n",
    "    padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "    # Via padded[:-1], we remove the extra padded token\n",
    "    # that has been added via the +1 setting in batch_max_length\n",
    "    # (the extra padding token will be relevant in later codes)\n",
    "    inputs = torch.tensor(padded[:-1])\n",
    "    inputs_lst.append(inputs)\n",
    "\n",
    "  # convert list of inputs to tensor and transfer to target device\n",
    "  inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "  return inputs_tensor"
   ],
   "metadata": {
    "id": "-cLhKLcJ7-oq"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wli2axML7-l_",
    "outputId": "e1c68556-515e-4c96-ab24-bb95b9f0407e"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- but that only for input, for target, everything must be shifted by +1:"
   ],
   "metadata": {
    "id": "xN3lXHsOHWlJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_2(batch,\n",
    "                           pad_token_id=50256,\n",
    "                           device=\"cpu\"):\n",
    "  # find the longest sequence in the batch and increase max_length\n",
    "  # by +1 for the padding token, which indicates the end of sequence/answer\n",
    "  batch_max_length = max(len(item) + 1 for item in batch)\n",
    "\n",
    "  # pad and prepare inputs\n",
    "  inputs_lst = []\n",
    "  targets_lst = []\n",
    "\n",
    "  for item in batch:\n",
    "    new_item = item.copy()\n",
    "    # Add an <|endoftext|> token\n",
    "    new_item += [pad_token_id]\n",
    "    # Pad sequences to batch_max_length\n",
    "    padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "\n",
    "    inputs = torch.tensor(padded[:-1]) # Truncate the last token for inputs\n",
    "    targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "    inputs_lst.append(inputs)\n",
    "    targets_lst.append(targets)\n",
    "\n",
    "  # convert list of inputs to tensor and transfer to target device\n",
    "  inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "  targets_tensor = torch.stack(targets_lst).to(device)\n",
    "  return inputs_tensor, targets_tensor"
   ],
   "metadata": {
    "id": "UFlBZb8g7-kO"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMzY15if7-hG",
    "outputId": "f9756868-ec0e-4f11-bc52-f730e2b411e8"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- now convert the unnecessary padding tokens in `targets` (not `inputs`)that don't signify the end of sequence into `ignore_index` so that they won't affect loss during training\n",
    "- also introduce the `allowed_max_length` in case we want to limit the length of the samples; this will be useful if you plan to work with your own datasets that are longer than the 1024 token context size supported by the GPT-2 model:"
   ],
   "metadata": {
    "id": "hzYmeojcIDVx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def custom_collate_fn(batch,\n",
    "                      pad_token_id=50256,\n",
    "                      ignore_index=-100,\n",
    "                      allowed_max_length=None,\n",
    "                      device=\"cpu\"):\n",
    "  # find the longest sequence in the batch and increase max_length\n",
    "  # by +1 for the padding token, which indicates the end of sequence/answer\n",
    "  batch_max_length = max(len(item) + 1 for item in batch)\n",
    "\n",
    "  # pad and prepare inputs\n",
    "  inputs_lst = []\n",
    "  targets_lst = []\n",
    "\n",
    "  for item in batch:\n",
    "    new_item = item.copy()\n",
    "    # Add an <|endoftext|> token\n",
    "    new_item += [pad_token_id]\n",
    "    # Pad sequences to batch_max_length\n",
    "    padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "\n",
    "    inputs = torch.tensor(padded[:-1]) # Truncate the last token for inputs\n",
    "    targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "    # replace all but the first padding tokens in targets by `ignore_index`\n",
    "    mask = targets == pad_token_id\n",
    "    padding_tokens_indices = torch.nonzero(mask).squeeze() # indices of the padding tokens in `targets`\n",
    "    if padding_tokens_indices.numel() > 1:\n",
    "      targets[padding_tokens_indices[1:]] = ignore_index\n",
    "\n",
    "    # optionally truncate to maximum sequence length\n",
    "    if allowed_max_length is not None:\n",
    "      inputs = inputs[:allowed_max_length]\n",
    "      targets = targets[:allowed_max_length]\n",
    "\n",
    "    inputs_lst.append(inputs)\n",
    "    targets_lst.append(targets)\n",
    "\n",
    "  # convert list of inputs to tensor and transfer to target device\n",
    "  inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "  targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "  return inputs_tensor, targets_tensor"
   ],
   "metadata": {
    "id": "GYb9LqKi7-ee"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWvVmLGI7-bn",
    "outputId": "05e25d2b-2ca3-41c7-b59a-b0390cb0f7d8"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- the reason why introduce `ignore_index`:"
   ],
   "metadata": {
    "id": "HA3qoDaCLbkf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],  # 1st training example\n",
    "     [-0.5, 1.5]]  # 2nd training example\n",
    ")\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "\n",
    "\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0ltRJxh7-Z9",
    "outputId": "5e93b03b-ad1f-4594-83d8-b34f8d862010"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# add more training example will influence the loss\n",
    "logits_2 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]  # New 3rd training example\n",
    ")\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KUpMEuOH7-WV",
    "outputId": "8c5dd2d6-cfce-4365-ecea-eb2fe915ce05"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# try to replace the class label of one of the examples with -100\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMEYyM8L7-Tl",
    "outputId": "f85c4d3c-8f1c-4493-9898-a5d3d7e9df5c"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Using this -100 `ignore_index`, we can ignore the additional end-of-text (padding) tokens in the batches that we used to pad the training examples to equal length\n",
    "- However, we don't want to ignore the first instance of the end-of-text (padding) token (50256) because it can help signal to the LLM when the response is complete"
   ],
   "metadata": {
    "id": "cmFFo4IgMVuH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Creating DataLoaders"
   ],
   "metadata": {
    "id": "JwqbUeQvMmIE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "id": "uGBLY66-7-Rz"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Using the `partial` function from Python's `functools` standard library, we create a new function with the `device` argument of the original function pre-filled:"
   ],
   "metadata": {
    "id": "urLw8B6oNrm1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ],
   "metadata": {
    "id": "ts683Hxn7-Ob"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Next, we instantiate the data loaders, and provide our own collate function for the batching process:"
   ],
   "metadata": {
    "id": "-BSlcI7_N3R6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ],
   "metadata": {
    "id": "TNqiSMgt7-L1"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhC_V2M57-JN",
    "outputId": "0e94dd9f-d8aa-41c0-ba64-c01f67883238"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(inputs[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYW0lKI37-Gi",
    "outputId": "0823f6e9-36b7-4420-f6a5-6f235fde1f97"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='cuda:0')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(targets[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQhbYaea7-E6",
    "outputId": "4d55c948-6a7c-4505-969d-9c2438ebd17c"
   },
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Loading a pretrained LLM"
   ],
   "metadata": {
    "id": "gUe3mfp5O8fz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ],
   "metadata": {
    "id": "_cr3b5OV7-Bk"
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0_78q1P7-AZ",
    "outputId": "cab5f111-08f8-453e-9057-5a6f6673f60d"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x7a50188f24d0>)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_embedding_dim,\n",
    "                 output_embedding_dim,\n",
    "                 context_length,\n",
    "                 dropout,\n",
    "                 num_heads,\n",
    "                 qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (output_embedding_dim % num_heads == 0), \\\n",
    "            \"output_embedding_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.output_embedding_dim = output_embedding_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = output_embedding_dim // num_heads\n",
    "        self.W_query = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
    "                                 bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
    "                               bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
    "                                 bias=qkv_bias)\n",
    "        self.output_projection = nn.Linear(output_embedding_dim,\n",
    "                                           output_embedding_dim)  # to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch, num_tokens, input_embedding_dim = inputs.shape\n",
    "\n",
    "        # qkv shapes : (batch, num_tokens, output_embedding_dim)\n",
    "        keys = self.W_key(inputs)\n",
    "        values = self.W_value(inputs)\n",
    "        queries = self.W_query(inputs)\n",
    "\n",
    "        # qkv shapes : (batch, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # qkv shapes : (batch, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "\n",
    "        # compute attention scores for each head\n",
    "        attention_scores = queries @ keys.transpose(3, 2)\n",
    "        attention_scores.masked_fill_(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], - torch.inf)\n",
    "\n",
    "        # compute attention weights + dropout\n",
    "        masked_attention_weight = torch.softmax(\n",
    "            attention_scores / (keys.shape[-1] ** 0.5),\n",
    "            dim=-1)\n",
    "        masked_attention_dropout_weight = self.dropout(masked_attention_weight)\n",
    "\n",
    "        # compute context vectors\n",
    "        # shape : (batch, num_tokens, num_heads, head_dim)\n",
    "        context_vector = (masked_attention_dropout_weight @ values).transpose(1, 2)\n",
    "\n",
    "        # combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        # shape : (batch, num_tokens, output_embedding_dim)\n",
    "        context_vector = context_vector.contiguous().view(\n",
    "            batch, num_tokens, self.output_embedding_dim)\n",
    "\n",
    "        # linear projection (optional)\n",
    "        context_vector = self.output_projection(context_vector)\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.epsilon = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1,\n",
    "                    unbiased=False,  # Bessel's correction (n-1)\n",
    "                    keepdim=True)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.epsilon)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config[\"emb_dim\"],  # 768\n",
    "                      4 * config[\"emb_dim\"]),  # 3072\n",
    "            GELU(),  # 3072\n",
    "            nn.Linear(4 * config[\"emb_dim\"],  # 3072\n",
    "                      config[\"emb_dim\"])  # 768\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(input_embedding_dim=config[\"emb_dim\"],\n",
    "                                            output_embedding_dim=config[\"emb_dim\"],\n",
    "                                            context_length=config[\"context_length\"],\n",
    "                                            dropout=config[\"drop_rate\"],\n",
    "                                            num_heads=config[\"n_heads\"],\n",
    "                                            qkv_bias=config[\"qkv_bias\"])\n",
    "        self.feed_forward = FeedForward(config)\n",
    "        self.layer_norm1 = LayerNorm(config[\"emb_dim\"])\n",
    "        self.layer_norm2 = LayerNorm(config[\"emb_dim\"])\n",
    "        self.drop_skip = nn.Dropout(config[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # skip connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.attention(x)  # shape: [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_skip(x)\n",
    "        x = shortcut + x  # skip connection\n",
    "\n",
    "        # skip connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = self.drop_skip(x)\n",
    "        x = shortcut + x  # skip connection\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPT2Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(config[\"vocab_size\"],\n",
    "                                      config[\"emb_dim\"])\n",
    "        self.position_emb = nn.Embedding(config[\"context_length\"],\n",
    "                                         config[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(config[\"drop_rate\"])\n",
    "\n",
    "        self.transformer_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(config) for _ in range(config[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(config[\"emb_dim\"])\n",
    "\n",
    "        self.out_head = nn.Linear(config[\"emb_dim\"],\n",
    "                                  config[\"vocab_size\"],\n",
    "                                  bias=False)\n",
    "\n",
    "    def forward(self, input_token):\n",
    "        batch_size, sequence_length = input_token.shape\n",
    "        token_embeds = self.token_emb(input_token)\n",
    "        position_embeds = self.position_emb(\n",
    "            torch.arange(sequence_length,\n",
    "                         device=input_token.device))\n",
    "        embeds = token_embeds + position_embeds\n",
    "        x = self.drop_emb(embeds)\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.position_emb.weight = assign(gpt.position_emb.weight, params['wpe'])\n",
    "    gpt.token_emb.weight = assign(gpt.token_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.transformer_blocks[b].attention.W_query.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_query.weight, q_w.T)\n",
    "        gpt.transformer_blocks[b].attention.W_key.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_key.weight, k_w.T)\n",
    "        gpt.transformer_blocks[b].attention.W_value.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.transformer_blocks[b].attention.W_query.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_query.bias, q_b)\n",
    "        gpt.transformer_blocks[b].attention.W_key.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_key.bias, k_b)\n",
    "        gpt.transformer_blocks[b].attention.W_value.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.W_value.bias, v_b)\n",
    "\n",
    "        gpt.transformer_blocks[b].attention.output_projection.weight = assign(\n",
    "            gpt.transformer_blocks[b].attention.output_projection.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformer_blocks[b].attention.output_projection.bias = assign(\n",
    "            gpt.transformer_blocks[b].attention.output_projection.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transformer_blocks[b].feed_forward.layers[0].weight = assign(\n",
    "            gpt.transformer_blocks[b].feed_forward.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.transformer_blocks[b].feed_forward.layers[0].bias = assign(\n",
    "            gpt.transformer_blocks[b].feed_forward.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.transformer_blocks[b].feed_forward.layers[2].weight = assign(\n",
    "            gpt.transformer_blocks[b].feed_forward.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.transformer_blocks[b].feed_forward.layers[2].bias = assign(\n",
    "            gpt.transformer_blocks[b].feed_forward.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.transformer_blocks[b].layer_norm1.scale = assign(\n",
    "            gpt.transformer_blocks[b].layer_norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.transformer_blocks[b].layer_norm1.shift = assign(\n",
    "            gpt.transformer_blocks[b].layer_norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.transformer_blocks[b].layer_norm2.scale = assign(\n",
    "            gpt.transformer_blocks[b].layer_norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.transformer_blocks[b].layer_norm2.shift = assign(\n",
    "            gpt.transformer_blocks[b].layer_norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ],
   "metadata": {
    "id": "9JGLuZGA798J"
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "model_size"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Ii4MOjnv7956",
    "outputId": "3dfcb521-46db-4c17-fb66-40aad1e72818"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'355M'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "print(settings)\n",
    "print(params.keys())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8UODHoF793d",
    "outputId": "9c3090ed-9675-4899-9d5d-ecf5a6458a05"
   },
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n",
      "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 1024, 'n_head': 16, 'n_layer': 24}\n",
      "dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = GPT2Model(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ],
   "metadata": {
    "id": "7uCzPgwu7906"
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's check whether the model generates coherent text:\n"
   ],
   "metadata": {
    "id": "5agFf23XQERi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "  # turn the list of token IDs into tensor with batch dimension\n",
    "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "  return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(encoded_tensor, tokenizer):\n",
    "  # turn tensor without batch dimension to list\n",
    "  token_ids = encoded_tensor.squeeze(0).tolist()\n",
    "  text = tokenizer.decode(token_ids)\n",
    "  return text\n",
    "\n",
    "\n",
    "def generate_text(model,\n",
    "                  input_batch,\n",
    "                  max_new_tokens,\n",
    "                  context_size,\n",
    "                  temperature=0.0,\n",
    "                  top_k=None,\n",
    "                  eos_id=None):\n",
    "  for _ in range(max_new_tokens):\n",
    "    # crop current context if it exceeds the supported context_size\n",
    "    crop_input_batch = input_batch[:, -context_size:]\n",
    "\n",
    "    # predict next token\n",
    "    with torch.no_grad():\n",
    "      logits = model(crop_input_batch)\n",
    "\n",
    "    # consider only logits of the last token\n",
    "    logits = logits[:, -1, :] # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
    "\n",
    "    # NEW: filter logits with top_k sampling\n",
    "    if top_k is not None:\n",
    "      # keep only top_k values\n",
    "      top_logits, _ = torch.topk(logits, top_k)\n",
    "      min_val = top_logits[:, -1] # min value among the top_k values\n",
    "      # all values other than top_k values will be set to -inf\n",
    "      logits = torch.where(logits < min_val,\n",
    "                           torch.tensor(-torch.inf).to(logits.device),\n",
    "                           logits)\n",
    "\n",
    "    # NEW: temperature scaling\n",
    "    if temperature > 0.0:\n",
    "      logits = logits / temperature\n",
    "\n",
    "      probas = torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
    "      predicted_tokens = torch.multinomial(probas, num_samples=1) # (batch, 1)\n",
    "\n",
    "    else: # same as before\n",
    "      #probas = torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
    "      predicted_tokens = torch.argmax(logits, dim=-1, keepdim=True) # (batch, 1)\n",
    "\n",
    "    if predicted_tokens == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "    # update input_batch (append predicted tokens to the sequences)\n",
    "    input_batch = torch.cat([input_batch, predicted_tokens], dim=1) # [batch, num_tokens+1]\n",
    "\n",
    "  return input_batch"
   ],
   "metadata": {
    "id": "Icbnz5wg79y-"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_1 = \"In the midst of winter\"\n",
    "\n",
    "token_ids = generate_text(\n",
    "    model=model,\n",
    "    input_batch=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    temperature = 2.0,\n",
    "    top_k = 10\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SS3aM68c79wc",
    "outputId": "1170e1d2-d426-47f0-d76e-88ed3b2f1936"
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In the midst of winter, we are not sure what the future looks like in these parts. But the people we have here are the best we're ever likely to be, the most talented we'll probably get, the hardest worker we're ever going to be. And we\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "- let's see how the model performs on one of the instruction tasks:",
   "metadata": {
    "id": "KPZEivrPQUsS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(211)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkXQkO_X79tD",
    "outputId": "24747ca3-fbad-4923-d92c-e45529c82d47"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "token_ids = generate_text(\n",
    "    model=model,\n",
    "    input_batch=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=100,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ],
   "metadata": {
    "id": "ypKsu06M79rA"
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generated_text"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "DlQ7MKN579oG",
    "outputId": "3df14cc1-da27-4132-f960-f26c382fa63a"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\n\\n### Response:\\n\\nThe chef cooks the meal every day.\\n\\n### Instruction:\\n\\n\""
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lF0laCvc79lr",
    "outputId": "07484b7b-cfcc-4700-fb8c-70de324b87d7"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Finetuning the LLM on instruction data"
   ],
   "metadata": {
    "id": "MddRsFU2RMe5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def calc_loss_batch(input_batch,\n",
    "                    target_batch,\n",
    "                    model,\n",
    "                    device):\n",
    "  input_batch = input_batch.to(device)\n",
    "  target_batch = target_batch.to(device)\n",
    "\n",
    "  logits = model(input_batch)\n",
    "  loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1),\n",
    "                                           target_batch.flatten())\n",
    "  return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(dataloader,\n",
    "                     model,\n",
    "                     device,\n",
    "                     num_batches=None):\n",
    "  total_loss = 0.\n",
    "  if len(dataloader) == 0:\n",
    "    return float(\"nan\")\n",
    "  elif num_batches is None:\n",
    "    num_batches = len(dataloader)\n",
    "  else:\n",
    "    # reduce the number of batches to match the total number of batches in the data loader\n",
    "    # if num_batches exceeds the number of batches in the data loader\n",
    "    num_batches = min(num_batches, len(dataloader))\n",
    "  for i, (input_batch, target_batch) in enumerate(dataloader):\n",
    "    if i < num_batches:\n",
    "      loss = calc_loss_batch(input_batch,\n",
    "                             target_batch,\n",
    "                             model,\n",
    "                             device)\n",
    "      total_loss += loss.item()\n",
    "    else:\n",
    "      break\n",
    "  return total_loss / num_batches"
   ],
   "metadata": {
    "id": "MM9I8vnE79jN"
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model,\n",
    "                    train_loader,\n",
    "                    val_loader,\n",
    "                    device,\n",
    "                    eval_iter):\n",
    "  # set model to evaluation mode\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    # calculate loss\n",
    "    train_loss = calc_loss_loader(train_loader,\n",
    "                                  model,\n",
    "                                  device,\n",
    "                                  num_batches=eval_iter)\n",
    "    val_loss = calc_loss_loader(val_loader,\n",
    "                                model,\n",
    "                                device,\n",
    "                                num_batches=eval_iter)\n",
    "\n",
    "  # set model back to training mode\n",
    "  model.train()\n",
    "  return train_loss, val_loss\n",
    "\n",
    "def generate_text_simple(model,\n",
    "                         input_batch,  # [batch, num_tokens]\n",
    "                         max_new_tokens,  # numbers of new tokens to be predicted\n",
    "                         context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        # crop current context if it exceeds the supported context_size\n",
    "        crop_input_batch = input_batch[:, -context_size:]\n",
    "\n",
    "        # predict next token\n",
    "        with torch.no_grad():\n",
    "            logits = model(crop_input_batch)\n",
    "\n",
    "        # consider only logits of the last token\n",
    "        logits = logits[:, -1, :]  # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "        predicted_tokens = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "        # update input_batch (append predicted tokens to the sequences)\n",
    "        input_batch = torch.cat([input_batch, predicted_tokens], dim=-1)  # [batch, num_tokens+1]\n",
    "\n",
    "    return input_batch\n",
    "\n",
    "\n",
    "def generate_text_advanced(model,\n",
    "                           input_batch,\n",
    "                           max_new_tokens,\n",
    "                           context_size,\n",
    "                           temperature=1.0,\n",
    "                           top_k=None,\n",
    "                           top_p=None,\n",
    "                           repetition_penalty=1.0,\n",
    "                           eos_id=None):\n",
    "    \"\"\"\n",
    "    Advanced text generation with multiple decoding strategies.\n",
    "\n",
    "    Args:\n",
    "        model: The language model\n",
    "        input_batch: Input token ids [batch_size, seq_len]\n",
    "        max_new_tokens: Number of tokens to generate\n",
    "        context_size: Maximum context length the model can handle\n",
    "        temperature: Sampling temperature (1.0 = neutral, <1.0 = more focused, >1.0 = more random)\n",
    "        top_k: If set, only sample from the top k most likely tokens\n",
    "        top_p: If set, sample from the smallest set of tokens whose cumulative probability exceeds p\n",
    "        repetition_penalty: Penalty for repeating tokens (1.0 = no penalty, >1.0 = penalize repetitions)\n",
    "        eos_id: Optional end of sequence token id to stop generation early\n",
    "\n",
    "    Returns:\n",
    "        Tensor of generated token ids [batch_size, seq_len + max_new_tokens]\n",
    "    \"\"\"\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Crop context if needed\n",
    "        crop_input_batch = input_batch[:, -context_size:]\n",
    "\n",
    "        # Get model predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(crop_input_batch)\n",
    "\n",
    "        # Consider only the last token's logits\n",
    "        logits = logits[:, -1, :]  # [batch_size, vocab_size]\n",
    "\n",
    "        # Apply repetition penalty\n",
    "        if repetition_penalty != 1.0:\n",
    "            # Get unique tokens in the input\n",
    "            used_tokens = torch.unique(input_batch)\n",
    "            # Penalize previously used tokens\n",
    "            logits.index_fill_(dim=-1, index=used_tokens,\n",
    "                               value=logits.index_select(dim=-1, index=used_tokens) / repetition_penalty)\n",
    "\n",
    "        # Apply temperature scaling\n",
    "        if temperature != 1.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "        # Convert to probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Apply top-k filtering\n",
    "        if top_k is not None:\n",
    "            top_k = min(top_k, logits.size(-1))\n",
    "            top_logits, top_indices = torch.topk(logits, top_k)\n",
    "            # Create a mask for non-top-k values\n",
    "            mask = torch.zeros_like(logits).scatter_(dim=-1, index=top_indices, value=1)\n",
    "            # Set non-top-k values to -inf before softmax\n",
    "            logits = torch.where(mask > 0, logits, torch.tensor(-float('inf')).to(logits.device))\n",
    "            # Recompute probabilities\n",
    "            probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Apply nucleus (top-p) sampling\n",
    "        if top_p is not None:\n",
    "            sorted_probas, sorted_indices = torch.sort(probas, descending=True)\n",
    "            cumsum_probas = torch.cumsum(sorted_probas, dim=-1)\n",
    "            # Remove tokens after cumsum exceeds top_p\n",
    "            mask = cumsum_probas <= top_p\n",
    "            # Always keep at least one token\n",
    "            mask[..., 0] = True\n",
    "            sorted_indices = sorted_indices[mask]\n",
    "            probas = torch.zeros_like(probas).scatter_(-1, sorted_indices, sorted_probas[mask])\n",
    "            probas.div_(probas.sum(dim=-1, keepdim=True))\n",
    "\n",
    "        # Sample next token\n",
    "        predicted_tokens = torch.multinomial(probas, num_samples=1)\n",
    "\n",
    "        # Stop if EOS token is generated\n",
    "        if eos_id is not None and (predicted_tokens == eos_id).any():\n",
    "            break\n",
    "\n",
    "        # Append prediction to input\n",
    "        input_batch = torch.cat([input_batch, predicted_tokens], dim=-1)\n",
    "\n",
    "    return input_batch\n",
    "\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model,\n",
    "                              tokenizer,\n",
    "                              device,\n",
    "                              start_context):\n",
    "  # set model to evaluation mode\n",
    "  model.eval()\n",
    "  context_size = model.position_emb.weight.shape[0]\n",
    "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "  with torch.no_grad():\n",
    "    token_ids = generate_text_simple(model=model,\n",
    "                                     input_batch=encoded,\n",
    "                                     max_new_tokens=50,\n",
    "                                     context_size=context_size)\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \")) # compact print format\n",
    "  # set model back to training mode\n",
    "  model.train()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model_simple(model,\n",
    "                       train_loader,\n",
    "                       val_loader,\n",
    "                       optimizer,\n",
    "                       device,\n",
    "                       num_epochs,\n",
    "                       eval_freq,\n",
    "                       eval_iter,\n",
    "                       start_context,\n",
    "                       tokenizer):\n",
    "\n",
    "  # initialize lists to track losses and tokens seen\n",
    "  train_losses = []\n",
    "  val_losses = []\n",
    "  track_tokens_seen = []\n",
    "  token_seen = 0\n",
    "  global_step = -1\n",
    "\n",
    "  # main training loop - iterate over training epochs\n",
    "  for epoch in range(num_epochs):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # iterate over batches in each training epoch\n",
    "    for input_batch, target_batch in train_loader:\n",
    "      # reset loss gradients from previous batch iteration\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # calculate loss on current batch\n",
    "      loss = calc_loss_batch(input_batch,\n",
    "                             target_batch,\n",
    "                             model,\n",
    "                             device)\n",
    "\n",
    "      # backward pass to calculate loss gradients\n",
    "      loss.backward()\n",
    "\n",
    "      # update model weights using loss gradients\n",
    "      optimizer.step()\n",
    "      token_seen += input_batch.numel()\n",
    "      global_step += 1\n",
    "\n",
    "      # optional evaluation step\n",
    "      if global_step % eval_freq == 0:\n",
    "        train_loss, val_loss = evaluate_model(model,\n",
    "                                              train_loader,\n",
    "                                              val_loader,\n",
    "                                              device,\n",
    "                                              eval_iter)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        track_tokens_seen.append(token_seen)\n",
    "        # print training and evaluation set loss\n",
    "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "              f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "    # generative sample text for visual inspection\n",
    "    generate_and_print_sample(model,\n",
    "                              tokenizer,\n",
    "                              device,\n",
    "                              start_context)\n",
    "\n",
    "  return train_losses, val_losses, track_tokens_seen"
   ],
   "metadata": {
    "id": "e3x4voug79et"
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's calculate the initial training and validation set loss before we start training:"
   ],
   "metadata": {
    "id": "j2AE85tcTHpt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODvKFp3q79b4",
    "outputId": "3ca6f2b2-8d6c-419c-8f4c-6ae11e556427"
   },
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training loss: 3.8259087562561036\n",
      "Validation loss: 3.761933708190918\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(211)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_MQWvEq79aR",
    "outputId": "5c1ac462-1f91-4fc2-9622-6e67b5c82198"
   },
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.645, Val loss 2.610\n",
      "Ep 1 (Step 000005): Train loss 1.134, Val loss 1.107\n",
      "Ep 1 (Step 000010): Train loss 0.917, Val loss 0.986\n",
      "Ep 1 (Step 000015): Train loss 0.775, Val loss 0.916\n",
      "Ep 1 (Step 000020): Train loss 0.788, Val loss 0.883\n",
      "Ep 1 (Step 000025): Train loss 0.690, Val loss 0.864\n",
      "Ep 1 (Step 000030): Train loss 0.744, Val loss 0.841\n",
      "Ep 1 (Step 000035): Train loss 0.642, Val loss 0.826\n",
      "Ep 1 (Step 000040): Train loss 0.710, Val loss 0.807\n",
      "Ep 1 (Step 000045): Train loss 0.614, Val loss 0.785\n",
      "Ep 1 (Step 000050): Train loss 0.695, Val loss 0.775\n",
      "Ep 1 (Step 000055): Train loss 0.595, Val loss 0.763\n",
      "Ep 1 (Step 000060): Train loss 0.615, Val loss 0.759\n",
      "Ep 1 (Step 000065): Train loss 0.574, Val loss 0.760\n",
      "Ep 1 (Step 000070): Train loss 0.672, Val loss 0.744\n",
      "Ep 1 (Step 000075): Train loss 0.538, Val loss 0.732\n",
      "Ep 1 (Step 000080): Train loss 0.570, Val loss 0.724\n",
      "Ep 1 (Step 000085): Train loss 0.481, Val loss 0.709\n",
      "Ep 1 (Step 000090): Train loss 0.503, Val loss 0.707\n",
      "Ep 1 (Step 000095): Train loss 0.556, Val loss 0.698\n",
      "Ep 1 (Step 000100): Train loss 0.528, Val loss 0.691\n",
      "Ep 1 (Step 000105): Train loss 0.487, Val loss 0.686\n",
      "Ep 1 (Step 000110): Train loss 0.499, Val loss 0.683\n",
      "Ep 1 (Step 000115): Train loss 0.531, Val loss 0.671\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Ep 2 (Step 000120): Train loss 0.428, Val loss 0.662\n",
      "Ep 2 (Step 000125): Train loss 0.482, Val loss 0.661\n",
      "Ep 2 (Step 000130): Train loss 0.417, Val loss 0.666\n",
      "Ep 2 (Step 000135): Train loss 0.411, Val loss 0.671\n",
      "Ep 2 (Step 000140): Train loss 0.423, Val loss 0.666\n",
      "Ep 2 (Step 000145): Train loss 0.379, Val loss 0.656\n",
      "Ep 2 (Step 000150): Train loss 0.410, Val loss 0.655\n",
      "Ep 2 (Step 000155): Train loss 0.376, Val loss 0.651\n",
      "Ep 2 (Step 000160): Train loss 0.455, Val loss 0.660\n",
      "Ep 2 (Step 000165): Train loss 0.367, Val loss 0.662\n",
      "Ep 2 (Step 000170): Train loss 0.392, Val loss 0.663\n",
      "Ep 2 (Step 000175): Train loss 0.397, Val loss 0.657\n",
      "Ep 2 (Step 000180): Train loss 0.345, Val loss 0.654\n",
      "Ep 2 (Step 000185): Train loss 0.379, Val loss 0.649\n",
      "Ep 2 (Step 000190): Train loss 0.360, Val loss 0.646\n",
      "Ep 2 (Step 000195): Train loss 0.377, Val loss 0.637\n",
      "Ep 2 (Step 000200): Train loss 0.366, Val loss 0.635\n",
      "Ep 2 (Step 000205): Train loss 0.332, Val loss 0.637\n",
      "Ep 2 (Step 000210): Train loss 0.301, Val loss 0.642\n",
      "Ep 2 (Step 000215): Train loss 0.349, Val loss 0.637\n",
      "Ep 2 (Step 000220): Train loss 0.344, Val loss 0.630\n",
      "Ep 2 (Step 000225): Train loss 0.339, Val loss 0.629\n",
      "Ep 2 (Step 000230): Train loss 0.327, Val loss 0.632\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The\n",
      "Ep 3 (Step 000235): Train loss 0.333, Val loss 0.651\n",
      "Ep 3 (Step 000240): Train loss 0.290, Val loss 0.678\n",
      "Ep 3 (Step 000245): Train loss 0.289, Val loss 0.710\n",
      "Ep 3 (Step 000250): Train loss 0.284, Val loss 0.710\n",
      "Ep 3 (Step 000255): Train loss 0.276, Val loss 0.710\n",
      "Ep 3 (Step 000260): Train loss 0.272, Val loss 0.709\n",
      "Ep 3 (Step 000265): Train loss 0.272, Val loss 0.686\n",
      "Ep 3 (Step 000270): Train loss 0.246, Val loss 0.674\n",
      "Ep 3 (Step 000275): Train loss 0.273, Val loss 0.678\n",
      "Ep 3 (Step 000280): Train loss 0.302, Val loss 0.675\n",
      "Ep 3 (Step 000285): Train loss 0.248, Val loss 0.690\n",
      "Ep 3 (Step 000290): Train loss 0.264, Val loss 0.698\n",
      "Ep 3 (Step 000295): Train loss 0.262, Val loss 0.698\n",
      "Ep 3 (Step 000300): Train loss 0.249, Val loss 0.688\n",
      "Ep 3 (Step 000305): Train loss 0.249, Val loss 0.690\n",
      "Ep 3 (Step 000310): Train loss 0.257, Val loss 0.695\n",
      "Ep 3 (Step 000315): Train loss 0.270, Val loss 0.698\n",
      "Ep 3 (Step 000320): Train loss 0.233, Val loss 0.696\n",
      "Ep 3 (Step 000325): Train loss 0.239, Val loss 0.695\n",
      "Ep 3 (Step 000330): Train loss 0.245, Val loss 0.694\n",
      "Ep 3 (Step 000335): Train loss 0.234, Val loss 0.686\n",
      "Ep 3 (Step 000340): Train loss 0.260, Val loss 0.665\n",
      "Ep 3 (Step 000345): Train loss 0.244, Val loss 0.658\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 4 (Step 000350): Train loss 0.227, Val loss 0.666\n",
      "Ep 4 (Step 000355): Train loss 0.240, Val loss 0.694\n",
      "Ep 4 (Step 000360): Train loss 0.252, Val loss 0.732\n",
      "Ep 4 (Step 000365): Train loss 0.233, Val loss 0.729\n",
      "Ep 4 (Step 000370): Train loss 0.216, Val loss 0.723\n",
      "Ep 4 (Step 000375): Train loss 0.228, Val loss 0.718\n",
      "Ep 4 (Step 000380): Train loss 0.237, Val loss 0.723\n",
      "Ep 4 (Step 000385): Train loss 0.215, Val loss 0.713\n",
      "Ep 4 (Step 000390): Train loss 0.218, Val loss 0.707\n",
      "Ep 4 (Step 000395): Train loss 0.217, Val loss 0.717\n",
      "Ep 4 (Step 000400): Train loss 0.235, Val loss 0.738\n",
      "Ep 4 (Step 000405): Train loss 0.221, Val loss 0.731\n",
      "Ep 4 (Step 000410): Train loss 0.205, Val loss 0.719\n",
      "Ep 4 (Step 000415): Train loss 0.214, Val loss 0.715\n",
      "Ep 4 (Step 000420): Train loss 0.225, Val loss 0.715\n",
      "Ep 4 (Step 000425): Train loss 0.206, Val loss 0.724\n",
      "Ep 4 (Step 000430): Train loss 0.229, Val loss 0.725\n",
      "Ep 4 (Step 000435): Train loss 0.192, Val loss 0.724\n",
      "Ep 4 (Step 000440): Train loss 0.193, Val loss 0.721\n",
      "Ep 4 (Step 000445): Train loss 0.224, Val loss 0.723\n",
      "Ep 4 (Step 000450): Train loss 0.214, Val loss 0.730\n",
      "Ep 4 (Step 000455): Train loss 0.210, Val loss 0.729\n",
      "Ep 4 (Step 000460): Train loss 0.200, Val loss 0.721\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared by the chef every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the boiling point of mercury in\n",
      "Ep 5 (Step 000465): Train loss 0.202, Val loss 0.718\n",
      "Ep 5 (Step 000470): Train loss 0.206, Val loss 0.732\n",
      "Ep 5 (Step 000475): Train loss 0.201, Val loss 0.747\n",
      "Ep 5 (Step 000480): Train loss 0.177, Val loss 0.764\n",
      "Ep 5 (Step 000485): Train loss 0.172, Val loss 0.760\n",
      "Ep 5 (Step 000490): Train loss 0.174, Val loss 0.746\n",
      "Ep 5 (Step 000495): Train loss 0.188, Val loss 0.744\n",
      "Ep 5 (Step 000500): Train loss 0.195, Val loss 0.744\n",
      "Ep 5 (Step 000505): Train loss 0.209, Val loss 0.744\n",
      "Ep 5 (Step 000510): Train loss 0.198, Val loss 0.755\n",
      "Ep 5 (Step 000515): Train loss 0.198, Val loss 0.759\n",
      "Ep 5 (Step 000520): Train loss 0.228, Val loss 0.748\n",
      "Ep 5 (Step 000525): Train loss 0.189, Val loss 0.745\n",
      "Ep 5 (Step 000530): Train loss 0.176, Val loss 0.753\n",
      "Ep 5 (Step 000535): Train loss 0.191, Val loss 0.759\n",
      "Ep 5 (Step 000540): Train loss 0.171, Val loss 0.750\n",
      "Ep 5 (Step 000545): Train loss 0.176, Val loss 0.739\n",
      "Ep 5 (Step 000550): Train loss 0.187, Val loss 0.749\n",
      "Ep 5 (Step 000555): Train loss 0.188, Val loss 0.734\n",
      "Ep 5 (Step 000560): Train loss 0.188, Val loss 0.727\n",
      "Ep 5 (Step 000565): Train loss 0.209, Val loss 0.738\n",
      "Ep 5 (Step 000570): Train loss 0.195, Val loss 0.705\n",
      "Ep 5 (Step 000575): Train loss 0.179, Val loss 0.709\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the boiling point of methane in Celsius?\n",
      "Ep 6 (Step 000580): Train loss 0.174, Val loss 0.719\n",
      "Ep 6 (Step 000585): Train loss 0.176, Val loss 0.742\n",
      "Ep 6 (Step 000590): Train loss 0.186, Val loss 0.784\n",
      "Ep 6 (Step 000595): Train loss 0.193, Val loss 0.801\n",
      "Ep 6 (Step 000600): Train loss 0.185, Val loss 0.786\n",
      "Ep 6 (Step 000605): Train loss 0.177, Val loss 0.761\n",
      "Ep 6 (Step 000610): Train loss 0.174, Val loss 0.740\n",
      "Ep 6 (Step 000615): Train loss 0.180, Val loss 0.740\n",
      "Ep 6 (Step 000620): Train loss 0.169, Val loss 0.755\n",
      "Ep 6 (Step 000625): Train loss 0.161, Val loss 0.755\n",
      "Ep 6 (Step 000630): Train loss 0.167, Val loss 0.748\n",
      "Ep 6 (Step 000635): Train loss 0.178, Val loss 0.755\n",
      "Ep 6 (Step 000640): Train loss 0.176, Val loss 0.759\n",
      "Ep 6 (Step 000645): Train loss 0.163, Val loss 0.746\n",
      "Ep 6 (Step 000650): Train loss 0.166, Val loss 0.730\n",
      "Ep 6 (Step 000655): Train loss 0.171, Val loss 0.728\n",
      "Ep 6 (Step 000660): Train loss 0.164, Val loss 0.748\n",
      "Ep 6 (Step 000665): Train loss 0.176, Val loss 0.758\n",
      "Ep 6 (Step 000670): Train loss 0.169, Val loss 0.766\n",
      "Ep 6 (Step 000675): Train loss 0.165, Val loss 0.773\n",
      "Ep 6 (Step 000680): Train loss 0.172, Val loss 0.765\n",
      "Ep 6 (Step 000685): Train loss 0.160, Val loss 0.752\n",
      "Ep 6 (Step 000690): Train loss 0.172, Val loss 0.757\n",
      "Ep 6 (Step 000695): Train loss 0.170, Val loss 0.757\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the opposite of 'light'?\n",
      "Ep 7 (Step 000700): Train loss 0.155, Val loss 0.759\n",
      "Ep 7 (Step 000705): Train loss 0.170, Val loss 0.777\n",
      "Ep 7 (Step 000710): Train loss 0.162, Val loss 0.800\n",
      "Ep 7 (Step 000715): Train loss 0.152, Val loss 0.814\n",
      "Ep 7 (Step 000720): Train loss 0.159, Val loss 0.822\n",
      "Ep 7 (Step 000725): Train loss 0.158, Val loss 0.823\n",
      "Ep 7 (Step 000730): Train loss 0.159, Val loss 0.803\n",
      "Ep 7 (Step 000735): Train loss 0.170, Val loss 0.776\n",
      "Ep 7 (Step 000740): Train loss 0.152, Val loss 0.768\n",
      "Ep 7 (Step 000745): Train loss 0.169, Val loss 0.760\n",
      "Ep 7 (Step 000750): Train loss 0.162, Val loss 0.763\n",
      "Ep 7 (Step 000755): Train loss 0.155, Val loss 0.771\n",
      "Ep 7 (Step 000760): Train loss 0.161, Val loss 0.780\n",
      "Ep 7 (Step 000765): Train loss 0.164, Val loss 0.774\n",
      "Ep 7 (Step 000770): Train loss 0.151, Val loss 0.773\n",
      "Ep 7 (Step 000775): Train loss 0.149, Val loss 0.772\n",
      "Ep 7 (Step 000780): Train loss 0.158, Val loss 0.775\n",
      "Ep 7 (Step 000785): Train loss 0.169, Val loss 0.774\n",
      "Ep 7 (Step 000790): Train loss 0.156, Val loss 0.752\n",
      "Ep 7 (Step 000795): Train loss 0.161, Val loss 0.745\n",
      "Ep 7 (Step 000800): Train loss 0.149, Val loss 0.748\n",
      "Ep 7 (Step 000805): Train loss 0.147, Val loss 0.743\n",
      "Ep 7 (Step 000810): Train loss 0.155, Val loss 0.741\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the following sentence to use a metaphor:\n",
      "Ep 8 (Step 000815): Train loss 0.155, Val loss 0.757\n",
      "Ep 8 (Step 000820): Train loss 0.154, Val loss 0.782\n",
      "Ep 8 (Step 000825): Train loss 0.134, Val loss 0.801\n",
      "Ep 8 (Step 000830): Train loss 0.162, Val loss 0.798\n",
      "Ep 8 (Step 000835): Train loss 0.156, Val loss 0.783\n",
      "Ep 8 (Step 000840): Train loss 0.152, Val loss 0.781\n",
      "Ep 8 (Step 000845): Train loss 0.159, Val loss 0.791\n",
      "Ep 8 (Step 000850): Train loss 0.166, Val loss 0.798\n",
      "Ep 8 (Step 000855): Train loss 0.156, Val loss 0.794\n",
      "Ep 8 (Step 000860): Train loss 0.161, Val loss 0.787\n",
      "Ep 8 (Step 000865): Train loss 0.156, Val loss 0.782\n",
      "Ep 8 (Step 000870): Train loss 0.157, Val loss 0.782\n",
      "Ep 8 (Step 000875): Train loss 0.147, Val loss 0.780\n",
      "Ep 8 (Step 000880): Train loss 0.152, Val loss 0.771\n",
      "Ep 8 (Step 000885): Train loss 0.150, Val loss 0.767\n",
      "Ep 8 (Step 000890): Train loss 0.155, Val loss 0.757\n",
      "Ep 8 (Step 000895): Train loss 0.154, Val loss 0.744\n",
      "Ep 8 (Step 000900): Train loss 0.159, Val loss 0.749\n",
      "Ep 8 (Step 000905): Train loss 0.149, Val loss 0.765\n",
      "Ep 8 (Step 000910): Train loss 0.144, Val loss 0.775\n",
      "Ep 8 (Step 000915): Train loss 0.147, Val loss 0.785\n",
      "Ep 8 (Step 000920): Train loss 0.142, Val loss 0.795\n",
      "Ep 8 (Step 000925): Train loss 0.148, Val loss 0.798\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The active sentence 'The chef cooks the meal every day' is 'The meal is cooked every day by the chef.'<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "Ep 9 (Step 000930): Train loss 0.143, Val loss 0.799\n",
      "Ep 9 (Step 000935): Train loss 0.157, Val loss 0.818\n",
      "Ep 9 (Step 000940): Train loss 0.155, Val loss 0.837\n",
      "Ep 9 (Step 000945): Train loss 0.164, Val loss 0.834\n",
      "Ep 9 (Step 000950): Train loss 0.156, Val loss 0.827\n",
      "Ep 9 (Step 000955): Train loss 0.152, Val loss 0.835\n",
      "Ep 9 (Step 000960): Train loss 0.152, Val loss 0.835\n",
      "Ep 9 (Step 000965): Train loss 0.162, Val loss 0.807\n",
      "Ep 9 (Step 000970): Train loss 0.158, Val loss 0.787\n",
      "Ep 9 (Step 000975): Train loss 0.155, Val loss 0.771\n",
      "Ep 9 (Step 000980): Train loss 0.160, Val loss 0.778\n",
      "Ep 9 (Step 000985): Train loss 0.153, Val loss 0.775\n",
      "Ep 9 (Step 000990): Train loss 0.151, Val loss 0.776\n",
      "Ep 9 (Step 000995): Train loss 0.150, Val loss 0.779\n",
      "Ep 9 (Step 001000): Train loss 0.147, Val loss 0.785\n",
      "Ep 9 (Step 001005): Train loss 0.144, Val loss 0.793\n",
      "Ep 9 (Step 001010): Train loss 0.153, Val loss 0.801\n",
      "Ep 9 (Step 001015): Train loss 0.147, Val loss 0.800\n",
      "Ep 9 (Step 001020): Train loss 0.144, Val loss 0.790\n",
      "Ep 9 (Step 001025): Train loss 0.147, Val loss 0.782\n",
      "Ep 9 (Step 001030): Train loss 0.147, Val loss 0.784\n",
      "Ep 9 (Step 001035): Train loss 0.137, Val loss 0.781\n",
      "Ep 9 (Step 001040): Train loss 0.156, Val loss 0.778\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the opposite of 'expensive'?  \n",
      "Ep 10 (Step 001045): Train loss 0.147, Val loss 0.776\n",
      "Ep 10 (Step 001050): Train loss 0.157, Val loss 0.789\n",
      "Ep 10 (Step 001055): Train loss 0.140, Val loss 0.800\n",
      "Ep 10 (Step 001060): Train loss 0.141, Val loss 0.803\n",
      "Ep 10 (Step 001065): Train loss 0.145, Val loss 0.816\n",
      "Ep 10 (Step 001070): Train loss 0.161, Val loss 0.825\n",
      "Ep 10 (Step 001075): Train loss 0.146, Val loss 0.818\n",
      "Ep 10 (Step 001080): Train loss 0.147, Val loss 0.803\n",
      "Ep 10 (Step 001085): Train loss 0.143, Val loss 0.807\n",
      "Ep 10 (Step 001090): Train loss 0.146, Val loss 0.816\n",
      "Ep 10 (Step 001095): Train loss 0.145, Val loss 0.829\n",
      "Ep 10 (Step 001100): Train loss 0.153, Val loss 0.840\n",
      "Ep 10 (Step 001105): Train loss 0.140, Val loss 0.847\n",
      "Ep 10 (Step 001110): Train loss 0.146, Val loss 0.845\n",
      "Ep 10 (Step 001115): Train loss 0.147, Val loss 0.832\n",
      "Ep 10 (Step 001120): Train loss 0.141, Val loss 0.814\n",
      "Ep 10 (Step 001125): Train loss 0.154, Val loss 0.796\n",
      "Ep 10 (Step 001130): Train loss 0.151, Val loss 0.794\n",
      "Ep 10 (Step 001135): Train loss 0.141, Val loss 0.801\n",
      "Ep 10 (Step 001140): Train loss 0.144, Val loss 0.814\n",
      "Ep 10 (Step 001145): Train loss 0.147, Val loss 0.826\n",
      "Ep 10 (Step 001150): Train loss 0.141, Val loss 0.826\n",
      "Ep 10 (Step 001155): Train loss 0.143, Val loss 0.820\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is a statement that describes a task. Write a response that appropriately completes the request.  ### Input: What is the capital of the United Kingdom? \n",
      "Training completed in 4.36 minutes.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epoch_seen,\n",
    "                tokens_seen,\n",
    "                train_losses,\n",
    "                val_losses,\n",
    "                fig_path=\"loss_plot.pdf\"):\n",
    "  \"\"\"Plot training and validation loss.\"\"\"\n",
    "\n",
    "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "  # plot training and validation loss against epochs\n",
    "  ax1.plot(epoch_seen, train_losses, label=\"Training Loss\")\n",
    "  ax1.plot(epoch_seen, val_losses, linestyle=\"-.\", label=\"Validation Loss\")\n",
    "  ax1.set_xlabel(\"Epoch\")\n",
    "  ax1.set_ylabel(\"Loss\")\n",
    "  ax1.legend(loc=\"upper right\")\n",
    "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) # only show integer labels on x-axis\n",
    "\n",
    "  # create a second x-axis for token seen\n",
    "  ax2 = ax1.twiny() # create a second x-axis that shares the same y-axis\n",
    "  ax2.plot(tokens_seen, train_losses, alpha=0) # invisible plot for aligning ticks\n",
    "  ax2.set_xlabel(\"Tokens Seen\")\n",
    "\n",
    "  fig.tight_layout() # adjust layout to make room\n",
    "  plt.savefig(fig_path)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "uYQs_6xr79W8",
    "outputId": "7ce97f39-ec81-42b9-f9a9-99a293c8d08f"
   },
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Extracting and saving responses"
   ],
   "metadata": {
    "id": "nUd9X8311BBn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(211)\n",
    "\n",
    "\n",
    "for entry in test_data[55:64]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate_text(\n",
    "        model=model,\n",
    "        input_batch=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"-------------------------------------\")\n",
    "    print(\"-------------------------------------\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HxS55ZMX79Ub",
    "outputId": "2cd0cb51-149c-4182-cda9-08c9080629e8"
   },
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Explain the primary function of the human heart.\n",
      "\n",
      "Correct response:\n",
      ">> The primary function of the human heart is to pump blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes.\n",
      "\n",
      "Model response:\n",
      ">> The primary function of the human heart is to pump blood to the body's tissues and to remove waste products. It includes the small vessels that supply the heart and the large vessels that supply the body with oxygen and nutrients.\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Reword the following sentence to the future tense.\n",
      "\n",
      "### Input:\n",
      "He is reading a novel inspired by his grandmother.\n",
      "\n",
      "Correct response:\n",
      ">> He will be reading a novel inspired by his grandmother.\n",
      "\n",
      "Model response:\n",
      ">> He is reading a novel inspired by his grandmother.\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the given sentence into active voice.\n",
      "\n",
      "### Input:\n",
      "The law was passed by the government.\n",
      "\n",
      "Correct response:\n",
      ">> The government passed the law.\n",
      "\n",
      "Model response:\n",
      ">> The law was passed by the government.\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Create a sentence using the word 'inevitable'.\n",
      "\n",
      "Correct response:\n",
      ">> The confrontation was inevitable given the circumstances.\n",
      "\n",
      "Model response:\n",
      ">> The collapse of the company was inevitable due to poor management.\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Categorize the following sentence as either factual or opinion-based.\n",
      "\n",
      "### Input:\n",
      "Chocolate is the best dessert.\n",
      "\n",
      "Correct response:\n",
      ">> Opinion-based.\n",
      "\n",
      "Model response:\n",
      ">> The statement is based on fact.\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'old'?\n",
      "\n",
      "Correct response:\n",
      ">> young.\n",
      "\n",
      "Model response:\n",
      ">> An antonym of 'old' is 'young'.\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Provide a synonym for 'hardworking'.\n",
      "\n",
      "Correct response:\n",
      ">> A synonym for 'hardworking' is 'diligent'.\n",
      "\n",
      "Model response:\n",
      ">> A synonym for 'hardworking' is 'sturdy'.\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the boiling point of sulfur in Celsius?\n",
      "\n",
      "Correct response:\n",
      ">> The boiling point of sulfur is 444.6 degrees Celsius.\n",
      "\n",
      "Model response:\n",
      ">> The boiling point of sulfur is -161.5 degrees Celsius.\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the plural form of 'child'?\n",
      "\n",
      "Correct response:\n",
      ">> The plural form of 'child' is 'children'.\n",
      "\n",
      "Model response:\n",
      ">> The plural form of 'child' is 'chunk.'\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "-------------------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- In the next section, we will use another LLM to evaluate the responses of our model; however, we will use our own test set instead of using a publicly available benchmark dataset\n",
    "\n",
    "- For this, we add the model response to the `test_data` dictionary and save it as a `\"instruction-data-with-response.json\"` file for record-keeping so that we can load and analyze it in separate Python sessions if needed"
   ],
   "metadata": {
    "id": "J6Dfg5UZ1xrG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Example entry:\\n\", test_data[50])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CNUKMNF45mo",
    "outputId": "4f16f79d-d389-4ea9-cb57-99e749a6fbe1"
   },
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Edit the given text to ensure all plural nouns are spelled correctly.', 'input': 'The birds sings beautiful songs.', 'output': 'The birds sing beautiful songs.'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# generate responses for whole dataset\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "  input_text = format_input(entry)\n",
    "\n",
    "  token_ids = generate_text(\n",
    "      model=model,\n",
    "      input_batch=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "      max_new_tokens=256,\n",
    "      context_size=BASE_CONFIG[\"context_length\"],\n",
    "      eos_id=50256)\n",
    "  generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "  response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "  # add \"model_response\" field into `test_data`\n",
    "  test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "# save `test_data` into .json file\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "  json.dump(test_data, file, indent=4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7pYieHx79SL",
    "outputId": "3046e1c6-cb01-4366-ea71-a1fdce11e852"
   },
   "execution_count": 46,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 110/110 [01:04<00:00,  1.70it/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(test_data[50])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gl2CCHut79P1",
    "outputId": "fb1ea23e-2b38-4b5d-d2e3-ff0a8a96c2eb"
   },
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'instruction': 'Edit the given text to ensure all plural nouns are spelled correctly.', 'input': 'The birds sings beautiful songs.', 'output': 'The birds sing beautiful songs.', 'model_response': 'The birds sings beautiful songs.'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- let's save the model:"
   ],
   "metadata": {
    "id": "KPfxYA_p6KG_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "\n",
    "# Load model via\n",
    "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TYUGwWWJ79Op",
    "outputId": "19d3200b-394c-462e-b950-cbf7f51f7d4c"
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model saved as gpt2-medium355M-sft.pth\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Evaluating the finetuned LLM"
   ],
   "metadata": {
    "id": "GNxqzkDH6gSE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- we'll use OpenAI model"
   ],
   "metadata": {
    "id": "A8i6yVeZ8lj1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"openai\",  # OpenAI API\n",
    "        \"tqdm\",    # Progress bar\n",
    "        ]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9J5Upsl6lcr",
    "outputId": "5ea56f6a-0080-4117-f264-63842a4f90cd"
   },
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "openai version: 1.86.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#!pip install dotenv"
   ],
   "metadata": {
    "id": "_UOHK3t61wgt"
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "\n",
    "client = OpenAI()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Q_S3mpI3Rtx",
    "outputId": "ca094f27-7449-4cf1-cbb2-3c319cb41848"
   },
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def run_chatgpt(prompt, client, model=MODEL):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0,\n",
    "        seed=123,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "prompt = \"Respond with 'hello world' if you got this message.\"\n",
    "run_chatgpt(prompt, client)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "8oJMk0x64B6W",
    "outputId": "ab194a89-d9be-4222-8610-3c5a4024a3e6"
   },
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'hello world'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 52
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for entry in test_data[55:64]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "        f\"Respond with the integer number only.\"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", run_chatgpt(prompt, client))\n",
    "    print(\"\\n-------------------------\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6i3xyNl56Jk",
    "outputId": "92fae891-bc29-495f-9e5a-c115679428bc"
   },
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The primary function of the human heart is to pump blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes.\n",
      "\n",
      "Model response:\n",
      ">> The primary function of the human heart is to pump blood to the body's tissues and to remove waste products. It includes the small vessels that supply the heart and the large vessels that supply the body with oxygen and nutrients.\n",
      "\n",
      "Score:\n",
      ">> 75\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> He will be reading a novel inspired by his grandmother.\n",
      "\n",
      "Model response:\n",
      ">> He is reading a novel inspired by his grandmother.\n",
      "\n",
      "Score:\n",
      ">> 0\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The government passed the law.\n",
      "\n",
      "Model response:\n",
      ">> The law was passed by the government.\n",
      "\n",
      "Score:\n",
      ">> 0\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The confrontation was inevitable given the circumstances.\n",
      "\n",
      "Model response:\n",
      ">> The collapse of the company was inevitable due to poor management.\n",
      "\n",
      "Score:\n",
      ">> 100\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Opinion-based.\n",
      "\n",
      "Model response:\n",
      ">> The statement is based on fact.\n",
      "\n",
      "Score:\n",
      ">> 0\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> young.\n",
      "\n",
      "Model response:\n",
      ">> An antonym of 'old' is 'young'.\n",
      "\n",
      "Score:\n",
      ">> 100\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> A synonym for 'hardworking' is 'diligent'.\n",
      "\n",
      "Model response:\n",
      ">> A synonym for 'hardworking' is 'sturdy'.\n",
      "\n",
      "Score:\n",
      ">> 20\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The boiling point of sulfur is 444.6 degrees Celsius.\n",
      "\n",
      "Model response:\n",
      ">> The boiling point of sulfur is -161.5 degrees Celsius.\n",
      "\n",
      "Score:\n",
      ">> 0\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The plural form of 'child' is 'children'.\n",
      "\n",
      "Model response:\n",
      ">> The plural form of 'child' is 'chunk.'\n",
      "\n",
      "Score:\n",
      ">> 0\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_model_scores(json_data, json_key, model=MODEL):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = run_chatgpt(prompt, client, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = generate_model_scores(test_data, \"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZ2hJxd-6pHf",
    "outputId": "ae7f9532-4515-4bc1-a99d-418bc67d20ff"
   },
   "execution_count": 54,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [00:38<00:00,  2.87it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 35.68\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "notebook_end_time = time.time()\n",
    "runtime_in_seconds = notebook_end_time - notebook_start_time\n",
    "\n",
    "# format as minutes and seconds\n",
    "minutes, seconds = divmod(runtime_in_seconds, 60)\n",
    "print(f\"Notebook runtime: {int(minutes)} min {seconds:.2f} sec\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FsNqFAw6-szi",
    "outputId": "75917648-f506-49f9-f079-8a1aa60b69b3"
   },
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Notebook runtime: 7 min 6.71 sec\n"
     ]
    }
   ]
  }
 ]
}
