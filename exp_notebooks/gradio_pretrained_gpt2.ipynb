{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qpacV6IHuWLH"
      },
      "outputs": [],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "91PJvcn3vZOu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. GPT2 Architecture"
      ],
      "metadata": {
        "id": "xrAAMF3fugyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1\n",
        "\n",
        "- Let's load:\n",
        "  1. `MultiHeadAttention` class\n",
        "  2. `LayerNorm` class\n",
        "  3. `GELU` class\n",
        "  4. `FeedForward` class\n",
        "  5. `TransformerBlock` class\n",
        "  6. `GPT2Model` class"
      ],
      "metadata": {
        "id": "NbVsuqzrulez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_embedding_dim,\n",
        "                 output_embedding_dim,\n",
        "                 context_length,\n",
        "                 dropout,\n",
        "                 num_heads,\n",
        "                 qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (output_embedding_dim % num_heads == 0), \\\n",
        "            \"output_embedding_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.output_embedding_dim = output_embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = output_embedding_dim // num_heads\n",
        "        self.W_query = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                                 bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                               bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(input_embedding_dim, output_embedding_dim,\n",
        "                                 bias=qkv_bias)\n",
        "        self.output_projection = nn.Linear(output_embedding_dim,\n",
        "                                           output_embedding_dim)  # to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch, num_tokens, input_embedding_dim = inputs.shape\n",
        "\n",
        "        # qkv shapes : (batch, num_tokens, output_embedding_dim)\n",
        "        keys = self.W_key(inputs)\n",
        "        values = self.W_value(inputs)\n",
        "        queries = self.W_query(inputs)\n",
        "\n",
        "        # qkv shapes : (batch, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(batch, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # qkv shapes : (batch, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "\n",
        "        # compute attention scores for each head\n",
        "        attention_scores = queries @ keys.transpose(3, 2)\n",
        "        attention_scores.masked_fill_(\n",
        "            self.mask.bool()[:num_tokens, :num_tokens], - torch.inf)\n",
        "\n",
        "        # compute attention weights + dropout\n",
        "        masked_attention_weight = torch.softmax(\n",
        "            attention_scores / (keys.shape[-1] ** 0.5),\n",
        "            dim=-1)\n",
        "        masked_attention_dropout_weight = self.dropout(masked_attention_weight)\n",
        "\n",
        "        # compute context vectors\n",
        "        # shape : (batch, num_tokens, num_heads, head_dim)\n",
        "        context_vector = (masked_attention_dropout_weight @ values).transpose(1, 2)\n",
        "\n",
        "        # combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        # shape : (batch, num_tokens, output_embedding_dim)\n",
        "        context_vector = context_vector.contiguous().view(\n",
        "            batch, num_tokens, self.output_embedding_dim)\n",
        "\n",
        "        # linear projection (optional)\n",
        "        context_vector = self.output_projection(context_vector)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.epsilon = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1,\n",
        "                    unbiased=False,  # Bessel's correction (n-1)\n",
        "                    keepdim=True)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.epsilon)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(config[\"emb_dim\"],  # 768\n",
        "                      4 * config[\"emb_dim\"]),  # 3072\n",
        "            GELU(),  # 3072\n",
        "            nn.Linear(4 * config[\"emb_dim\"],  # 3072\n",
        "                      config[\"emb_dim\"])  # 768\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = MultiHeadAttention(input_embedding_dim=config[\"emb_dim\"],\n",
        "                                            output_embedding_dim=config[\"emb_dim\"],\n",
        "                                            context_length=config[\"context_length\"],\n",
        "                                            dropout=config[\"drop_rate\"],\n",
        "                                            num_heads=config[\"n_heads\"],\n",
        "                                            qkv_bias=config[\"qkv_bias\"])\n",
        "        self.feed_forward = FeedForward(config)\n",
        "        self.layer_norm1 = LayerNorm(config[\"emb_dim\"])\n",
        "        self.layer_norm2 = LayerNorm(config[\"emb_dim\"])\n",
        "        self.drop_skip = nn.Dropout(config[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # skip connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.layer_norm1(x)\n",
        "        x = self.attention(x)  # shape: [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_skip(x)\n",
        "        x = shortcut + x  # skip connection\n",
        "\n",
        "        # skip connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.drop_skip(x)\n",
        "        x = shortcut + x  # skip connection\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPT2Model(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.token_emb = nn.Embedding(config[\"vocab_size\"],\n",
        "                                      config[\"emb_dim\"])\n",
        "        self.position_emb = nn.Embedding(config[\"context_length\"],\n",
        "                                         config[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(config[\"drop_rate\"])\n",
        "\n",
        "        self.transformer_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(config) for _ in range(config[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(config[\"emb_dim\"])\n",
        "\n",
        "        self.out_head = nn.Linear(config[\"emb_dim\"],\n",
        "                                  config[\"vocab_size\"],\n",
        "                                  bias=False)\n",
        "\n",
        "    def forward(self, input_token):\n",
        "        batch_size, sequence_length = input_token.shape\n",
        "        token_embeds = self.token_emb(input_token)\n",
        "        position_embeds = self.position_emb(\n",
        "            torch.arange(sequence_length,\n",
        "                         device=input_token.device))\n",
        "        embeds = token_embeds + position_embeds\n",
        "        x = self.drop_emb(embeds)\n",
        "        x = self.transformer_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GPT2DatasetV1(Dataset):\n",
        "  def __init__(self,\n",
        "               text,\n",
        "               tokenizer,\n",
        "               context_length, # length of each input vector\n",
        "               stride # chunk the text into overlapping sequence of context_length\n",
        "               ):\n",
        "    self.input_id_vectors = []\n",
        "    self.target_id_vectors = []\n",
        "\n",
        "    # tokenize the entire text\n",
        "    token_list = tokenizer.encode(text)\n",
        "\n",
        "    # append input and target vectors\n",
        "    for i in range(0, len(token_list) - context_length, stride):\n",
        "      input_vector = token_list[i:i+context_length]\n",
        "      target_vector = token_list[i+1:i+context_length+1]\n",
        "      self.input_id_vectors.append(torch.tensor(input_vector))\n",
        "      self.target_id_vectors.append(torch.tensor(target_vector))\n",
        "\n",
        "  # get the number of input vectors\n",
        "  def __len__(self):\n",
        "    return len(self.input_id_vectors)\n",
        "\n",
        "  # return the (input vector, target vector) pair\n",
        "  def __getitem__(self, id):\n",
        "    return self.input_id_vectors[id], self.target_id_vectors[id]\n",
        "\n",
        "\n",
        "\n",
        "def create_dataloader_V1(text,\n",
        "                 batch_size=4,\n",
        "                 context_length=256,\n",
        "                 stride=128,\n",
        "                 shuffle=True, # shuffle dataset\n",
        "                 drop_last=True, # drop last batch if it not equal required size\n",
        "                 num_workers=0 # number of CPU processes for preprocessing\n",
        "                 ):\n",
        "\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "  dataset = GPT2DatasetV1(text=text,\n",
        "                          tokenizer=tokenizer,\n",
        "                          context_length=context_length,\n",
        "                          stride=stride)\n",
        "\n",
        "  dataloader = DataLoader(dataset=dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=shuffle,\n",
        "                          drop_last=drop_last,\n",
        "                          num_workers=num_workers)\n",
        "\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "y4Py46X4uaay"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Training and Evaluation Functions\n",
        "\n",
        "- Let's load:\n",
        "  1. `train_model_simple`: without warmup rate, cosine decay, gradient clipping\n",
        "  2. `train_model`\n",
        "  3. `evaluate_model`"
      ],
      "metadata": {
        "id": "K9gMF509u4Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_model_simple(model,\n",
        "                       train_loader,\n",
        "                       val_loader,\n",
        "                       optimizer,\n",
        "                       device,\n",
        "                       num_epochs,\n",
        "                       eval_freq,\n",
        "                       eval_iter,\n",
        "                       start_context,\n",
        "                       tokenizer):\n",
        "\n",
        "  # initialize lists to track losses and tokens seen\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "  track_tokens_seen = []\n",
        "  token_seen = 0\n",
        "  global_step = -1\n",
        "\n",
        "  # main training loop - iterate over training epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate over batches in each training epoch\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      # reset loss gradients from previous batch iteration\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # calculate loss on current batch\n",
        "      loss = calc_loss_batch(input_batch,\n",
        "                             target_batch,\n",
        "                             model,\n",
        "                             device)\n",
        "\n",
        "      # backward pass to calculate loss gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # update model weights using loss gradients\n",
        "      optimizer.step()\n",
        "      token_seen += input_batch.numel()\n",
        "      global_step += 1\n",
        "\n",
        "      # optional evaluation step\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model,\n",
        "                                              train_loader,\n",
        "                                              val_loader,\n",
        "                                              device,\n",
        "                                              eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(token_seen)\n",
        "        # print training and evaluation set loss\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "              f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "    # generative sample text for visual inspection\n",
        "    generate_and_print_sample(model,\n",
        "                              tokenizer,\n",
        "                              device,\n",
        "                              start_context)\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ORIG_BOOK_VERSION = False\n",
        "def train_model(model,\n",
        "                train_loader,\n",
        "                val_loader,\n",
        "                optimizer,\n",
        "                device,\n",
        "                n_epochs,\n",
        "                eval_freq,\n",
        "                eval_iter,\n",
        "                start_context,\n",
        "                tokenizer,\n",
        "                warmup_steps,\n",
        "                initial_lr=3e-05,\n",
        "                min_lr=1e-6):\n",
        "\n",
        "  train_losses, val_losses = [], []\n",
        "  track_tokens_seen, track_lrs = [], []\n",
        "\n",
        "  token_seen = 0\n",
        "  global_step = -1\n",
        "\n",
        "  # retrieve the maximum/peak learning rate from the optimizer\n",
        "  peak_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "  # calculate the total number of iterations in the training process\n",
        "  total_training_steps = len(train_loader) * n_epochs\n",
        "\n",
        "  # calculate the learning rate increment during the warmup phase\n",
        "  lr_increment = (peak_lr - initial_lr) / warmup_steps\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      global_step += 1\n",
        "\n",
        "      # adjust the learning rate based on the current phase (warmup or cosine)\n",
        "      if global_step < warmup_steps:\n",
        "        lr = initial_lr + global_step * lr_increment\n",
        "      else:\n",
        "        # cosine annealing after warmup\n",
        "        progress = ((global_step - warmup_steps) /\n",
        "                    (total_training_steps - warmup_steps))\n",
        "        lr = (min_lr +\n",
        "         (peak_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress)))\n",
        "\n",
        "      # apply the calculated learning rate to the optimizer\n",
        "      for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "      track_lrs.append(lr) # store the current learning rate\n",
        "\n",
        "      # calculate and backpropagate the loss\n",
        "      loss = calc_loss_batch(input_batch,\n",
        "                             target_batch,\n",
        "                             model,\n",
        "                             device)\n",
        "      loss.backward()\n",
        "\n",
        "      # apply gradient clipping after the warmup phase to avoid exploding gradients\n",
        "      if ORIG_BOOK_VERSION:\n",
        "        if global_step > warmup_steps:\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "      else:\n",
        "        # the book originally used global_step > warmup_steps, which led to a skipped clipping step after warmup\n",
        "        if global_step >= warmup_steps:\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "      optimizer.step()\n",
        "      token_seen += input_batch.numel()\n",
        "\n",
        "      # periodically evaluate the model on the training and validation sets\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model,\n",
        "                                              train_loader,\n",
        "                                              val_loader,\n",
        "                                              device,\n",
        "                                              eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        track_tokens_seen.append(token_seen)\n",
        "        # print the current losses\n",
        "        print(f\"Ep {epoch+1} (Iter {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, \"\n",
        "                      f\"Val loss {val_loss:.3f}\")\n",
        "\n",
        "    # generate and print a sample from the model to monitor progess\n",
        "    generate_and_print_sample(\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device=device,\n",
        "        start_context=start_context\n",
        "    )\n",
        "\n",
        "  return train_losses, val_losses, track_tokens_seen, track_lrs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model(model,\n",
        "                    train_loader,\n",
        "                    val_loader,\n",
        "                    device,\n",
        "                    eval_iter):\n",
        "  # set model to evaluation mode\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    # calculate loss\n",
        "    train_loss = calc_loss_loader(train_loader,\n",
        "                                  model,\n",
        "                                  device,\n",
        "                                  num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader,\n",
        "                                model,\n",
        "                                device,\n",
        "                                num_batches=eval_iter)\n",
        "\n",
        "  # set model back to training mode\n",
        "  model.train()\n",
        "  return train_loss, val_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "\n",
        "\n",
        "def calc_loss_batch(input_batch,\n",
        "                    target_batch,\n",
        "                    model,\n",
        "                    device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "\n",
        "  logits = model(input_batch)\n",
        "  loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1),\n",
        "                                           target_batch.flatten())\n",
        "  return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(dataloader,\n",
        "                     model,\n",
        "                     device,\n",
        "                     num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(dataloader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(dataloader)\n",
        "  else:\n",
        "    # reduce the number of batches to match the total number of batches in the data loader\n",
        "    # if num_batches exceeds the number of batches in the data loader\n",
        "    num_batches = min(num_batches, len(dataloader))\n",
        "  for i, (input_batch, target_batch) in enumerate(dataloader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(input_batch,\n",
        "                             target_batch,\n",
        "                             model,\n",
        "                             device)\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches\n",
        "\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model,\n",
        "                              tokenizer,\n",
        "                              device,\n",
        "                              start_context):\n",
        "  # set model to evaluation mode\n",
        "  model.eval()\n",
        "  context_size = model.position_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    token_ids = generate_text_simple(model=model,\n",
        "                                     input_batch=encoded,\n",
        "                                     max_new_tokens=50,\n",
        "                                     context_size=context_size)\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \")) # compact print format\n",
        "  # set model back to training mode\n",
        "  model.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "  # turn the list of token IDs into tensor with batch dimension\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(encoded_tensor, tokenizer):\n",
        "  # turn tensor without batch dimension to list\n",
        "  token_ids = encoded_tensor.squeeze(0).tolist()\n",
        "  text = tokenizer.decode(token_ids)\n",
        "  return text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_text_simple(model,\n",
        "                         input_batch,  # [batch, num_tokens]\n",
        "                         max_new_tokens,  # numbers of new tokens to be predicted\n",
        "                         context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        # crop current context if it exceeds the supported context_size\n",
        "        crop_input_batch = input_batch[:, -context_size:]\n",
        "\n",
        "        # predict next token\n",
        "        with torch.no_grad():\n",
        "            logits = model(crop_input_batch)\n",
        "\n",
        "        # consider only logits of the last token\n",
        "        logits = logits[:, -1, :]  # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "        predicted_tokens = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "        # update input_batch (append predicted tokens to the sequences)\n",
        "        input_batch = torch.cat([input_batch, predicted_tokens], dim=-1)  # [batch, num_tokens+1]\n",
        "\n",
        "    return input_batch\n",
        "\n",
        "\n",
        "\n",
        "def generate_text(model,\n",
        "                  input_batch,\n",
        "                  max_new_tokens,\n",
        "                  context_size,\n",
        "                  temperature=0.0,\n",
        "                  top_k=None,\n",
        "                  eos_id=None):\n",
        "  for _ in range(max_new_tokens):\n",
        "    # crop current context if it exceeds the supported context_size\n",
        "    crop_input_batch = input_batch[:, -context_size:]\n",
        "\n",
        "    # predict next token\n",
        "    with torch.no_grad():\n",
        "      logits = model(crop_input_batch)\n",
        "\n",
        "    # consider only logits of the last token\n",
        "    logits = logits[:, -1, :] # (batch, n_tokens, vocab_size) -> (batch, vocab_size)\n",
        "\n",
        "    # NEW: filter logits with top_k sampling\n",
        "    if top_k is not None:\n",
        "      # keep only top_k values\n",
        "      top_logits, _ = torch.topk(logits, top_k)\n",
        "      min_val = top_logits[:, -1] # min value among the top_k values\n",
        "      # all values other than top_k values will be set to -inf\n",
        "      logits = torch.where(logits < min_val,\n",
        "                           torch.tensor(-torch.inf).to(logits.device),\n",
        "                           logits)\n",
        "\n",
        "    # NEW: temperature scaling\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "\n",
        "      probas = torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
        "      predicted_tokens = torch.multinomial(probas, num_samples=1) # (batch, 1)\n",
        "\n",
        "    else: # same as before\n",
        "      #probas = torch.softmax(logits, dim=-1) # (batch, vocab_size)\n",
        "      predicted_tokens = torch.argmax(logits, dim=-1, keepdim=True) # (batch, 1)\n",
        "\n",
        "    if predicted_tokens == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "    # update input_batch (append predicted tokens to the sequences)\n",
        "    input_batch = torch.cat([input_batch, predicted_tokens], dim=1) # [batch, num_tokens+1]\n",
        "\n",
        "  return input_batch\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################\n",
        "############################### utils functions #############################"
      ],
      "metadata": {
        "id": "7aAorxrHuaYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 LoRA layer"
      ],
      "metadata": {
        "id": "2ujalGwqvNov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "\n",
        "class LoRALayer(torch.nn.Module):\n",
        "  def __init__(self, in_dim, out_dim, rank, alpha):\n",
        "    super().__init__()\n",
        "    self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
        "    # Kaiming/He uniform initialization, similar to standard weight initialization\n",
        "    torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
        "    self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
        "    self.alpha = alpha\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.alpha * (x @ self.A @ self.B)\n",
        "    return x\n",
        "\n",
        "\n",
        "class LinearLayerWithLoRA(torch.nn.Module):\n",
        "  def __init__(self, linear, rank, alpha):\n",
        "    super().__init__()\n",
        "    self.linear = linear\n",
        "    self.lora = LoRALayer(linear.in_features,\n",
        "                          linear.out_features,\n",
        "                          rank,\n",
        "                          alpha)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x) + self.lora(x)\n",
        "\n",
        "\n",
        "\n",
        "def replace_linear_with_lora(model, rank, alpha):\n",
        "  for name, module in model.named_children():\n",
        "    if isinstance(module, torch.nn.Linear):\n",
        "      print(f\"Replacing {name} with LinearLayerWithLoRA\")\n",
        "      setattr(model, name, LinearLayerWithLoRA(module, rank, alpha))\n",
        "    else:\n",
        "      # recursively apply the same function to child modules\n",
        "      replace_linear_with_lora(module, rank, alpha)"
      ],
      "metadata": {
        "id": "gkGLSDbguaVh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Dataset\n",
        "- We'll use `war-and-peace.txt` dataset"
      ],
      "metadata": {
        "id": "F8M8MdgZvwXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Gradio app"
      ],
      "metadata": {
        "id": "I5WNdNN6v2Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Training"
      ],
      "metadata": {
        "id": "iTtg3Hibv5DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup\n",
        "file_path = \"war_and_peace.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "\n",
        "total_characters = len(text)\n",
        "bpe_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "total_tokens = len(bpe_tokenizer.encode(text))\n",
        "print(f\"total characters: {total_characters}\")\n",
        "print(f\"total tokens: {total_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-gmAbfkwkMP",
        "outputId": "af9ee8f6-f4e7-4dff-970f-e981f96558cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total characters: 3227520\n",
            "total tokens: 853923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "train_ratio = 0.90\n",
        "split_id = int(train_ratio * len(text))\n",
        "train_text = text[:split_id]\n",
        "val_text = text[split_id:]"
      ],
      "metadata": {
        "id": "UEt9TZLAxLZ0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloaders\n",
        "torch.manual_seed(211)\n",
        "\n",
        "\n",
        "train_dataloader = create_dataloader_V1(text=train_text,\n",
        "                                        batch_size=8,\n",
        "                                        context_length=BASE_CONFIG[\"context_length\"],\n",
        "                                        stride=BASE_CONFIG['context_length'],\n",
        "                                        shuffle=True,\n",
        "                                        drop_last=True,\n",
        "                                        num_workers=0)\n",
        "\n",
        "val_dataloader = create_dataloader_V1(text=val_text,\n",
        "                                      batch_size=8,\n",
        "                                      context_length=BASE_CONFIG[\"context_length\"],\n",
        "                                      stride=BASE_CONFIG['context_length'],\n",
        "                                      shuffle=False,\n",
        "                                      drop_last=False,\n",
        "                                      num_workers=0)"
      ],
      "metadata": {
        "id": "UyQpOzKZwkJw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "\n",
        "if total_tokens * (train_ratio) < BASE_CONFIG[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < BASE_CONFIG[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"decrease the `training_ratio`\")"
      ],
      "metadata": {
        "id": "CT8p3XgLwkG9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Clean up GPU memory ---\n",
        "import gc\n",
        "# del train_loss, val_loss  # if you don't need them anymore\n",
        "#del train_dataloader, val_dataloader  # optional, if not reused\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ],
      "metadata": {
        "id": "7Td2MTPJuaTB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2Model(BASE_CONFIG)"
      ],
      "metadata": {
        "id": "HAH6SrY7uaQv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compute initial losses!!!\n",
        "import time\n",
        "compute_loss_start_time = time.time()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_dataloader,\n",
        "                                model,\n",
        "                                device)\n",
        "  val_loss = calc_loss_loader(val_dataloader,\n",
        "                              model,\n",
        "                              device)\n",
        "\n",
        "print(f\"train loss: {train_loss:.4f}\")\n",
        "print(f\"validation loss: {val_loss:.4f}\")\n",
        "\n",
        "\n",
        "compute_loss_end_time = time.time()\n",
        "runtime_in_seconds = compute_loss_end_time - compute_loss_start_time\n",
        "# format as minutes and seconds\n",
        "minutes, seconds = divmod(runtime_in_seconds, 60)\n",
        "print(f\"compute_loss runtime: {int(minutes)} min {seconds:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfRhOuF4wj_h",
        "outputId": "38d97af7-06d7-4013-eccc-bd8d5bfd1529"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 10.9779\n",
            "validation loss: 10.9860\n",
            "compute_loss runtime: 0 min 20.55 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters before: {total_params:,}\")\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters after: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr-w1tmEuaOU",
        "outputId": "5f36ee28-96cf-42f7-a216-03f84cfbe443"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable parameters before: 163,037,184\n",
            "Total trainable parameters after: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "replace_linear_with_lora(model, rank=16, alpha=16)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqV7Ej7EuaMN",
        "outputId": "154326f7-b08e-4c20-f833-77b9ad2ece36"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing out_head with LinearLayerWithLoRA\n",
            "Total trainable LoRA parameters: 3,470,608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bQJ5GwguaJ6",
        "outputId": "b141627d-f6d5-44f7-a313-f079c3e3f8e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Model(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (position_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (transformer_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): LinearLayerWithLoRA(\n",
              "    (linear): Linear(in_features=768, out_features=50257, bias=False)\n",
              "    (lora): LoRALayer()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "initial_lr = 0.0001\n",
        "peak_lr = 3e-5\n",
        "\n",
        "\n",
        "total_steps = len(train_dataloader) * num_epochs\n",
        "warmup_steps = int(0.2 * total_steps) # 20% warmup\n",
        "print(warmup_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W0eSdq8uaHn",
        "outputId": "c5f3b2b0-f639-4330-ac28-5740eeb3a327"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "training_start_time = time.time()\n",
        "\n",
        "torch.manual_seed(211)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                              lr=peak_lr,\n",
        "                              weight_decay=0.01)\n",
        "\n",
        "train_losses, val_losses, tokens_seen, track_lrs = train_model(model=model,\n",
        "                                                    train_loader=train_dataloader,\n",
        "                                                    val_loader=val_dataloader,\n",
        "                                                    optimizer=optimizer,\n",
        "                                                    device=device,\n",
        "                                                    n_epochs=num_epochs,\n",
        "                                                    eval_freq=5,\n",
        "                                                    eval_iter=5,\n",
        "                                                    start_context=\"In the midst of winter, I found\",\n",
        "                                                    tokenizer=bpe_tokenizer,\n",
        "                                                    warmup_steps=warmup_steps,\n",
        "                                                    initial_lr=1e-5,\n",
        "                                                    min_lr=1e-5)\n",
        "\n",
        "\n",
        "training_end_time = time.time()\n",
        "runtime_in_seconds = training_end_time - training_start_time\n",
        "# format as minutes and seconds\n",
        "minutes, seconds = divmod(runtime_in_seconds, 60)\n",
        "print(f\"device: {device}\")\n",
        "print(f\"training runtime: {int(minutes)} min {seconds:.2f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvSWJWE8uaFM",
        "outputId": "f1857481-5bbb-423a-be76-44b0c5de11af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Iter 000000): Train loss 10.912, Val loss 10.916\n",
            "Ep 1 (Iter 000005): Train loss 10.532, Val loss 10.537\n",
            "Ep 1 (Iter 000010): Train loss 9.872, Val loss 9.903\n",
            "Ep 1 (Iter 000015): Train loss 9.156, Val loss 9.183\n",
            "Ep 1 (Iter 000020): Train loss 8.557, Val loss 8.578\n",
            "Ep 1 (Iter 000025): Train loss 7.958, Val loss 7.950\n",
            "Ep 1 (Iter 000030): Train loss 7.379, Val loss 7.364\n",
            "Ep 1 (Iter 000035): Train loss 7.032, Val loss 6.949\n",
            "Ep 1 (Iter 000040): Train loss 6.710, Val loss 6.701\n",
            "Ep 1 (Iter 000045): Train loss 6.526, Val loss 6.562\n",
            "Ep 1 (Iter 000050): Train loss 6.411, Val loss 6.514\n",
            "Ep 1 (Iter 000055): Train loss 6.445, Val loss 6.499\n",
            "Ep 1 (Iter 000060): Train loss 6.541, Val loss 6.480\n",
            "Ep 1 (Iter 000065): Train loss 6.447, Val loss 6.459\n",
            "Ep 1 (Iter 000070): Train loss 6.374, Val loss 6.440\n",
            "Ep 1 (Iter 000075): Train loss 6.249, Val loss 6.413\n",
            "Ep 1 (Iter 000080): Train loss 6.327, Val loss 6.376\n",
            "Ep 1 (Iter 000085): Train loss 6.361, Val loss 6.345\n",
            "Ep 1 (Iter 000090): Train loss 6.209, Val loss 6.320\n",
            "In the midst of winter, I found, and   ”         ” ’s   “, and, and    ”    ”    ’s\n",
            "Ep 2 (Iter 000095): Train loss 6.185, Val loss 6.300\n",
            "Ep 2 (Iter 000100): Train loss 6.223, Val loss 6.290\n",
            "Ep 2 (Iter 000105): Train loss 6.171, Val loss 6.277\n",
            "Ep 2 (Iter 000110): Train loss 6.204, Val loss 6.261\n",
            "Ep 2 (Iter 000115): Train loss 6.196, Val loss 6.232\n",
            "Ep 2 (Iter 000120): Train loss 6.135, Val loss 6.202\n",
            "Ep 2 (Iter 000125): Train loss 6.076, Val loss 6.166\n",
            "Ep 2 (Iter 000130): Train loss 6.097, Val loss 6.128\n",
            "Ep 2 (Iter 000135): Train loss 5.994, Val loss 6.098\n",
            "Ep 2 (Iter 000140): Train loss 6.015, Val loss 6.067\n",
            "Ep 2 (Iter 000145): Train loss 6.011, Val loss 6.046\n",
            "Ep 2 (Iter 000150): Train loss 5.985, Val loss 6.025\n",
            "Ep 2 (Iter 000155): Train loss 5.907, Val loss 6.004\n",
            "Ep 2 (Iter 000160): Train loss 5.856, Val loss 5.990\n",
            "Ep 2 (Iter 000165): Train loss 5.881, Val loss 5.974\n",
            "Ep 2 (Iter 000170): Train loss 5.783, Val loss 5.950\n",
            "Ep 2 (Iter 000175): Train loss 6.016, Val loss 5.922\n",
            "Ep 2 (Iter 000180): Train loss 5.785, Val loss 5.896\n",
            "Ep 2 (Iter 000185): Train loss 5.822, Val loss 5.872\n",
            "In the midst of winter, I found            ” ” said the “I, and the   ’s,” he was, and the ” he had been, and the \n",
            "Ep 3 (Iter 000190): Train loss 5.728, Val loss 5.868\n",
            "Ep 3 (Iter 000195): Train loss 5.916, Val loss 5.891\n",
            "Ep 3 (Iter 000200): Train loss 5.795, Val loss 5.895\n",
            "Ep 3 (Iter 000205): Train loss 5.807, Val loss 5.884\n",
            "Ep 3 (Iter 000210): Train loss 5.806, Val loss 5.871\n",
            "Ep 3 (Iter 000215): Train loss 5.754, Val loss 5.861\n",
            "Ep 3 (Iter 000220): Train loss 5.776, Val loss 5.852\n",
            "Ep 3 (Iter 000225): Train loss 5.774, Val loss 5.845\n",
            "Ep 3 (Iter 000230): Train loss 5.683, Val loss 5.838\n",
            "Ep 3 (Iter 000235): Train loss 5.711, Val loss 5.832\n",
            "Ep 3 (Iter 000240): Train loss 5.874, Val loss 5.826\n",
            "Ep 3 (Iter 000245): Train loss 5.832, Val loss 5.822\n",
            "Ep 3 (Iter 000250): Train loss 5.795, Val loss 5.818\n",
            "Ep 3 (Iter 000255): Train loss 5.763, Val loss 5.815\n",
            "Ep 3 (Iter 000260): Train loss 5.764, Val loss 5.813\n",
            "Ep 3 (Iter 000265): Train loss 5.699, Val loss 5.810\n",
            "Ep 3 (Iter 000270): Train loss 5.801, Val loss 5.808\n",
            "Ep 3 (Iter 000275): Train loss 5.760, Val loss 5.806\n",
            "Ep 3 (Iter 000280): Train loss 5.718, Val loss 5.804\n",
            "In the midst of winter, I found, and                        ” “I, and the      ” said the “I,\n",
            "Ep 4 (Iter 000285): Train loss 5.671, Val loss 5.803\n",
            "Ep 4 (Iter 000290): Train loss 5.800, Val loss 5.802\n",
            "Ep 4 (Iter 000295): Train loss 5.708, Val loss 5.800\n",
            "Ep 4 (Iter 000300): Train loss 5.623, Val loss 5.799\n",
            "Ep 4 (Iter 000305): Train loss 5.664, Val loss 5.797\n",
            "Ep 4 (Iter 000310): Train loss 5.732, Val loss 5.795\n",
            "Ep 4 (Iter 000315): Train loss 5.679, Val loss 5.795\n",
            "Ep 4 (Iter 000320): Train loss 5.659, Val loss 5.793\n",
            "Ep 4 (Iter 000325): Train loss 5.649, Val loss 5.791\n",
            "Ep 4 (Iter 000330): Train loss 5.749, Val loss 5.789\n",
            "Ep 4 (Iter 000335): Train loss 5.663, Val loss 5.787\n",
            "Ep 4 (Iter 000340): Train loss 5.661, Val loss 5.786\n",
            "Ep 4 (Iter 000345): Train loss 5.731, Val loss 5.785\n",
            "Ep 4 (Iter 000350): Train loss 5.737, Val loss 5.783\n",
            "Ep 4 (Iter 000355): Train loss 5.702, Val loss 5.783\n",
            "Ep 4 (Iter 000360): Train loss 5.783, Val loss 5.782\n",
            "Ep 4 (Iter 000365): Train loss 5.696, Val loss 5.781\n",
            "Ep 4 (Iter 000370): Train loss 5.690, Val loss 5.779\n",
            "Ep 4 (Iter 000375): Train loss 5.651, Val loss 5.777\n",
            "In the midst of winter, I found, and                        ” he, and the ” he was, and the ” said the ” he had\n",
            "Ep 5 (Iter 000380): Train loss 5.624, Val loss 5.775\n",
            "Ep 5 (Iter 000385): Train loss 5.617, Val loss 5.774\n",
            "Ep 5 (Iter 000390): Train loss 5.576, Val loss 5.774\n",
            "Ep 5 (Iter 000395): Train loss 5.655, Val loss 5.773\n",
            "Ep 5 (Iter 000400): Train loss 5.623, Val loss 5.773\n",
            "Ep 5 (Iter 000405): Train loss 5.641, Val loss 5.772\n",
            "Ep 5 (Iter 000410): Train loss 5.616, Val loss 5.770\n",
            "Ep 5 (Iter 000415): Train loss 5.595, Val loss 5.769\n",
            "Ep 5 (Iter 000420): Train loss 5.677, Val loss 5.769\n",
            "Ep 5 (Iter 000425): Train loss 5.661, Val loss 5.769\n",
            "Ep 5 (Iter 000430): Train loss 5.703, Val loss 5.767\n",
            "Ep 5 (Iter 000435): Train loss 5.645, Val loss 5.766\n",
            "Ep 5 (Iter 000440): Train loss 5.668, Val loss 5.763\n",
            "Ep 5 (Iter 000445): Train loss 5.582, Val loss 5.761\n",
            "Ep 5 (Iter 000450): Train loss 5.619, Val loss 5.759\n",
            "Ep 5 (Iter 000455): Train loss 5.607, Val loss 5.757\n",
            "Ep 5 (Iter 000460): Train loss 5.657, Val loss 5.756\n",
            "Ep 5 (Iter 000465): Train loss 5.760, Val loss 5.753\n",
            "In the midst of winter, I found, and                  “I, and the   “I, and the      ” said the ” said the\n",
            "Ep 6 (Iter 000470): Train loss 5.686, Val loss 5.751\n",
            "Ep 6 (Iter 000475): Train loss 5.743, Val loss 5.750\n",
            "Ep 6 (Iter 000480): Train loss 5.633, Val loss 5.749\n",
            "Ep 6 (Iter 000485): Train loss 5.588, Val loss 5.747\n",
            "Ep 6 (Iter 000490): Train loss 5.661, Val loss 5.746\n",
            "Ep 6 (Iter 000495): Train loss 5.662, Val loss 5.744\n",
            "Ep 6 (Iter 000500): Train loss 5.675, Val loss 5.743\n",
            "Ep 6 (Iter 000505): Train loss 5.579, Val loss 5.742\n",
            "Ep 6 (Iter 000510): Train loss 5.524, Val loss 5.742\n",
            "Ep 6 (Iter 000515): Train loss 5.643, Val loss 5.741\n",
            "Ep 6 (Iter 000520): Train loss 5.670, Val loss 5.739\n",
            "Ep 6 (Iter 000525): Train loss 5.542, Val loss 5.738\n",
            "Ep 6 (Iter 000530): Train loss 5.671, Val loss 5.737\n",
            "Ep 6 (Iter 000535): Train loss 5.634, Val loss 5.736\n",
            "Ep 6 (Iter 000540): Train loss 5.459, Val loss 5.734\n",
            "Ep 6 (Iter 000545): Train loss 5.578, Val loss 5.733\n",
            "Ep 6 (Iter 000550): Train loss 5.590, Val loss 5.732\n",
            "Ep 6 (Iter 000555): Train loss 5.567, Val loss 5.731\n",
            "Ep 6 (Iter 000560): Train loss 5.588, Val loss 5.730\n",
            "In the midst of winter, I found            ” said, and the  “I, and the   “I,” said the    ” said the ” said the\n",
            "Ep 7 (Iter 000565): Train loss 5.654, Val loss 5.729\n",
            "Ep 7 (Iter 000570): Train loss 5.532, Val loss 5.728\n",
            "Ep 7 (Iter 000575): Train loss 5.690, Val loss 5.726\n",
            "Ep 7 (Iter 000580): Train loss 5.662, Val loss 5.725\n",
            "Ep 7 (Iter 000585): Train loss 5.478, Val loss 5.723\n",
            "Ep 7 (Iter 000590): Train loss 5.590, Val loss 5.721\n",
            "Ep 7 (Iter 000595): Train loss 5.464, Val loss 5.720\n",
            "Ep 7 (Iter 000600): Train loss 5.589, Val loss 5.719\n",
            "Ep 7 (Iter 000605): Train loss 5.668, Val loss 5.718\n",
            "Ep 7 (Iter 000610): Train loss 5.663, Val loss 5.718\n",
            "Ep 7 (Iter 000615): Train loss 5.646, Val loss 5.717\n",
            "Ep 7 (Iter 000620): Train loss 5.574, Val loss 5.717\n",
            "Ep 7 (Iter 000625): Train loss 5.526, Val loss 5.717\n",
            "Ep 7 (Iter 000630): Train loss 5.565, Val loss 5.716\n",
            "Ep 7 (Iter 000635): Train loss 5.673, Val loss 5.714\n",
            "Ep 7 (Iter 000640): Train loss 5.617, Val loss 5.713\n",
            "Ep 7 (Iter 000645): Train loss 5.590, Val loss 5.712\n",
            "Ep 7 (Iter 000650): Train loss 5.560, Val loss 5.710\n",
            "Ep 7 (Iter 000655): Train loss 5.618, Val loss 5.709\n",
            "In the midst of winter, I found,           ” said, and the  “I, and the   “I, and the      ” said the ” said the\n",
            "Ep 8 (Iter 000660): Train loss 5.597, Val loss 5.708\n",
            "Ep 8 (Iter 000665): Train loss 5.524, Val loss 5.708\n",
            "Ep 8 (Iter 000670): Train loss 5.558, Val loss 5.708\n",
            "Ep 8 (Iter 000675): Train loss 5.561, Val loss 5.708\n",
            "Ep 8 (Iter 000680): Train loss 5.671, Val loss 5.706\n",
            "Ep 8 (Iter 000685): Train loss 5.475, Val loss 5.705\n",
            "Ep 8 (Iter 000690): Train loss 5.601, Val loss 5.703\n",
            "Ep 8 (Iter 000695): Train loss 5.640, Val loss 5.702\n",
            "Ep 8 (Iter 000700): Train loss 5.670, Val loss 5.701\n",
            "Ep 8 (Iter 000705): Train loss 5.537, Val loss 5.700\n",
            "Ep 8 (Iter 000710): Train loss 5.515, Val loss 5.698\n",
            "Ep 8 (Iter 000715): Train loss 5.545, Val loss 5.697\n",
            "Ep 8 (Iter 000720): Train loss 5.586, Val loss 5.696\n",
            "Ep 8 (Iter 000725): Train loss 5.530, Val loss 5.695\n",
            "Ep 8 (Iter 000730): Train loss 5.527, Val loss 5.694\n",
            "Ep 8 (Iter 000735): Train loss 5.589, Val loss 5.694\n",
            "Ep 8 (Iter 000740): Train loss 5.624, Val loss 5.693\n",
            "Ep 8 (Iter 000745): Train loss 5.592, Val loss 5.691\n",
            "Ep 8 (Iter 000750): Train loss 5.579, Val loss 5.689\n",
            "In the midst of winter, I found,           ” said the    “I, and the   “I, and the      ” said the ” said the\n",
            "Ep 9 (Iter 000755): Train loss 5.597, Val loss 5.688\n",
            "Ep 9 (Iter 000760): Train loss 5.549, Val loss 5.687\n",
            "Ep 9 (Iter 000765): Train loss 5.557, Val loss 5.686\n",
            "Ep 9 (Iter 000770): Train loss 5.548, Val loss 5.684\n",
            "Ep 9 (Iter 000775): Train loss 5.452, Val loss 5.684\n",
            "Ep 9 (Iter 000780): Train loss 5.513, Val loss 5.684\n",
            "Ep 9 (Iter 000785): Train loss 5.561, Val loss 5.682\n",
            "Ep 9 (Iter 000790): Train loss 5.565, Val loss 5.681\n",
            "Ep 9 (Iter 000795): Train loss 5.589, Val loss 5.681\n",
            "Ep 9 (Iter 000800): Train loss 5.526, Val loss 5.681\n",
            "Ep 9 (Iter 000805): Train loss 5.576, Val loss 5.681\n",
            "Ep 9 (Iter 000810): Train loss 5.458, Val loss 5.679\n",
            "Ep 9 (Iter 000815): Train loss 5.629, Val loss 5.678\n",
            "Ep 9 (Iter 000820): Train loss 5.560, Val loss 5.677\n",
            "Ep 9 (Iter 000825): Train loss 5.456, Val loss 5.677\n",
            "Ep 9 (Iter 000830): Train loss 5.499, Val loss 5.677\n",
            "Ep 9 (Iter 000835): Train loss 5.441, Val loss 5.676\n",
            "Ep 9 (Iter 000840): Train loss 5.450, Val loss 5.675\n",
            "Ep 9 (Iter 000845): Train loss 5.596, Val loss 5.674\n",
            "In the midst of winter, I found         ’s, and the     “I, and the   “I, and the      ” said the ” said the\n",
            "Ep 10 (Iter 000850): Train loss 5.460, Val loss 5.675\n",
            "Ep 10 (Iter 000855): Train loss 5.519, Val loss 5.673\n",
            "Ep 10 (Iter 000860): Train loss 5.492, Val loss 5.671\n",
            "Ep 10 (Iter 000865): Train loss 5.473, Val loss 5.668\n",
            "Ep 10 (Iter 000870): Train loss 5.495, Val loss 5.667\n",
            "Ep 10 (Iter 000875): Train loss 5.392, Val loss 5.668\n",
            "Ep 10 (Iter 000880): Train loss 5.599, Val loss 5.670\n",
            "Ep 10 (Iter 000885): Train loss 5.446, Val loss 5.668\n",
            "Ep 10 (Iter 000890): Train loss 5.572, Val loss 5.667\n",
            "Ep 10 (Iter 000895): Train loss 5.422, Val loss 5.666\n",
            "Ep 10 (Iter 000900): Train loss 5.485, Val loss 5.666\n",
            "Ep 10 (Iter 000905): Train loss 5.435, Val loss 5.666\n",
            "Ep 10 (Iter 000910): Train loss 5.512, Val loss 5.665\n",
            "Ep 10 (Iter 000915): Train loss 5.471, Val loss 5.665\n",
            "Ep 10 (Iter 000920): Train loss 5.547, Val loss 5.663\n",
            "Ep 10 (Iter 000925): Train loss 5.496, Val loss 5.663\n",
            "Ep 10 (Iter 000930): Train loss 5.560, Val loss 5.662\n",
            "Ep 10 (Iter 000935): Train loss 5.511, Val loss 5.661\n",
            "In the midst of winter, I found        the room, and the             “I, and the ” said the    ” said the ” said the\n",
            "device: cuda\n",
            "training runtime: 15 min 20.45 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.plot(range(len(track_lrs)), track_lrs)\n",
        "plt.ylabel(\"Learning rate\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "MJhcsLUluaDY",
        "outputId": "4dc4f75e-543d-4baa-8489-aa7da5f44a34"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's plot a loss graph:\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_losses(epoch_seen,\n",
        "                tokens_seen,\n",
        "                train_losses,\n",
        "                val_losses):\n",
        "  \"\"\"Plot training and validation loss in xkcd style.\"\"\"\n",
        "\n",
        "  fig, ax1 = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "  # plot training and validation loss against epochs\n",
        "  ax1.plot(epoch_seen, train_losses, label=\"Training Loss\")\n",
        "  ax1.plot(epoch_seen, val_losses, linestyle=\"-.\", label=\"Validation Loss\")\n",
        "  ax1.set_xlabel(\"Epoch\")\n",
        "  ax1.set_ylabel(\"Loss\")\n",
        "  ax1.legend(loc=\"upper right\")\n",
        "  ax1.xaxis.set_major_locator(MaxNLocator(integer=True)) # only show integer labels on x-axis\n",
        "\n",
        "  # create a second x-axis for token seen\n",
        "  ax2 = ax1.twiny() # create a second x-axis that shares the same y-axis\n",
        "  ax2.plot(tokens_seen, train_losses, alpha=0) # invisible plot for aligning ticks\n",
        "  ax2.set_xlabel(\"Tokens Seen\")\n",
        "\n",
        "  fig.tight_layout() # asjust layput to make room\n",
        "  plt.savefig(\"stable_training_with_lora_loss_plot.png\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "6cZoXMmKuaBG",
        "outputId": "d9b341ed-3cd6-4660-ef92-aa9549dae0d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()\n",
        "\n",
        "bpe_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(model=model,\n",
        "                                 input_batch=text_to_token_ids(\"In the midst of winter, I found\",\n",
        "                                                               bpe_tokenizer),\n",
        "                                 max_new_tokens=20,\n",
        "                                 context_size=BASE_CONFIG[\"context_length\"]\n",
        "                                 )\n",
        "\n",
        "\n",
        "print(\"output text: \\n\", token_ids_to_text(token_ids, bpe_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX_n8zTawQ7H",
        "outputId": "79e63d8a-4a58-4262-aeaa-118cd3f28704"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output text: \n",
            " In the midst of winter, I found\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the room, and the\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model state_dict\n",
        "torch.save(model.state_dict(), \"stable_training_with_lora_gpt2.pth\")"
      ],
      "metadata": {
        "id": "qJPHtb6fwQ4z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model state_dict\n",
        "\n",
        "bpe_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "model = GPT2Model(BASE_CONFIG)\n",
        "replace_linear_with_lora(model, rank=16, alpha=16)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"stable_training_with_lora_gpt2.pth\", map_location=device, weights_only=True))\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL2d9PgrwQ2l",
        "outputId": "531e7c79-fe8e-4f73-942c-d4dc828b0f3d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing W_query with LinearLayerWithLoRA\n",
            "Replacing W_key with LinearLayerWithLoRA\n",
            "Replacing W_value with LinearLayerWithLoRA\n",
            "Replacing output_projection with LinearLayerWithLoRA\n",
            "Replacing 0 with LinearLayerWithLoRA\n",
            "Replacing 2 with LinearLayerWithLoRA\n",
            "Replacing out_head with LinearLayerWithLoRA\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2Model(\n",
              "  (token_emb): Embedding(50257, 768)\n",
              "  (position_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (transformer_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (attention): MultiHeadAttention(\n",
              "        (W_query): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_key): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (W_value): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (output_projection): LinearLayerWithLoRA(\n",
              "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (lora): LoRALayer()\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (feed_forward): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "          (1): GELU()\n",
              "          (2): LinearLayerWithLoRA(\n",
              "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (lora): LoRALayer()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm()\n",
              "      (layer_norm2): LayerNorm()\n",
              "      (drop_skip): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): LinearLayerWithLoRA(\n",
              "    (linear): Linear(in_features=768, out_features=50257, bias=False)\n",
              "    (lora): LoRALayer()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Gradio"
      ],
      "metadata": {
        "id": "Y3ghwQd4yILL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pdf2image"
      ],
      "metadata": {
        "id": "9_ix_hLg6jNS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pdf2image import convert_from_path\n",
        "\n",
        "# # convert page 1 of your PDF to a PIL image\n",
        "# pages = convert_from_path(\"stable_training_with_lora_loss_plot.pdf\", dpi=200)\n",
        "# diagram_img = pages[0]\n",
        "# diagram_img.save(\"stable_training_with_lora_loss_plot.png\", \"PNG\")"
      ],
      "metadata": {
        "id": "7ER35BdH6nML"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "def generate_answer(input_prompt,\n",
        "                    #model,\n",
        "                    max_new_tokens,\n",
        "                    top_k,\n",
        "                    temperature,\n",
        "                    ):\n",
        "\n",
        "  # start the timer\n",
        "  start_time = time.time()\n",
        "\n",
        "  torch.manual_seed(211)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  token_ids = generate_text(\n",
        "      model=model,\n",
        "      input_batch=text_to_token_ids(input_prompt, bpe_tokenizer).to(device),\n",
        "      max_new_tokens=max_new_tokens,\n",
        "      context_size=BASE_CONFIG[\"context_length\"],\n",
        "      top_k=top_k,\n",
        "      temperature=temperature\n",
        "  )\n",
        "\n",
        "  # Calculate the prediction time\n",
        "  pred_time = round(time.time() - start_time)\n",
        "\n",
        "  # print(\"Output text:\\n\", token_ids_to_text(token_ids, bpe_tokenizer))\n",
        "  return token_ids_to_text(token_ids, bpe_tokenizer), pred_time"
      ],
      "metadata": {
        "id": "Cc_3VfpVwQ0E"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Create title, description and article strings\n",
        "title = \"GPT2 From Scratch\"\n",
        "description = \"Pretrained GPT2 (124M) from scratch with LoRA.\"\n",
        "article = \"Learning LLM from scratch\"\n",
        "\n",
        "\n",
        "# Create the Gradio demo\n",
        "demo = gr.Interface(fn=generate_answer, # mapping function from input to output\n",
        "                    inputs=[\n",
        "                        gr.Textbox(label=\"Input Text\"),\n",
        "                        gr.Slider(minimum=0, maximum=500, step=1, value=50, label=\"Choose number of generating tokens\"),\n",
        "                        gr.Slider(minimum=0, maximum=50, step=1, value=10, label=\"Choose top k\"),\n",
        "                        gr.Slider(minimum=0.0, maximum=5.0, step=0.1, value=1.5, label=\"Choose temperature\"),\n",
        "                        ],\n",
        "                    outputs=[\n",
        "                        gr.Textbox(label=\"Result\"),\n",
        "                        gr.Number(label=\"Time Taken (s)\"),\n",
        "                        gr.Image(label=\"Training Loss\"),\n",
        "                        ],\n",
        "                    #examples=example_list,\n",
        "                    title=title,\n",
        "                    description=description,\n",
        "                    article=article,\n",
        "                    )\n",
        "\n",
        "# Launch the demo!\n",
        "demo.launch(debug=True, # print errors locally?\n",
        "            share=True) # generate a publically shareable URL?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "juGI1K76wQxu",
        "outputId": "c76a3150-1e84-49b6-d466-180c1c0a2030"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://abb9b3728f18ab0d30.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://abb9b3728f18ab0d30.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://abb9b3728f18ab0d30.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BrOzhL2wAt2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}